# -*- Org -*-
# 
# Copyright (c) 2021, Hiroyuki Ohsaki.
# All rights reserved.
# 

# This document is licensed under a Creative Commons
# Attribution-NonCommercial-ShareAlike 4.0 International License (CC
# BY-NC-SA 4.0).

# This document is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# Creative Commons License for more details.

# You should have received a copy of the license along with this work.
# If not, see <http://creativecommons.org/licenses/by-nc-sa/4.0/>.

* 数の表現
<<ch:number>>

** 10 進数と 60 進数
<<sec:number/decimal>>

私たちの普段の生活では *10 進数 (decimal number)* が広く使われています。
10 進数とは、
*10 進法 (decimal system)* という、
各桁を 0 から 9 の文字を用いて表す数です。
年齢の数え方 (例: 22 歳) や、
お金の数え方 (例: 1 980 円)、
長さの表現 (例: 1.4 km)、
重さの表現 (例: 58 kg) など、
日常生活では主に 10 進数が使われています。
なぜ 10 進数がこれほど普及したのかは定かではないようですが、
一説には (あくまで一説ですが) 「人間の手の指が 10 本だったから 10 進数を使うようになった」と言われています。

小学校で学ぶ算数でも、
中学校から学ぶ数学でも、
理科でも、
社会でも、
ほぼすべての場面で 10 進数が使われているため、
ほとんどの人が 10 進数に慣れ親しんでいます。
一方、
10 進数以外の 2 進数や 16 進数にはあまりなじみがない人が多いでしょう。

10 進数の他には、
時間の長さを表すために *60 進数* が広く使われています。
例えば 1 時間 23 分 45 秒 (01:23:45) は、
1 桁目が 45、
2 桁目が 23、
3 桁目が 1 であるような 60 進数と見なすことができます。
1 時間 23 分 45 秒 (01:23:45) は秒に換算すると 5 025 秒であり、
これは、
\begin{align}
  & 60^2 \times 1 + 60^1 \times 23 + 60^0 \times 45 \notag \\
  = & 3600 + 1380 + 45  \\
  = & 5025
\end{align}
という計算によって得られます。

#+begin_note
「時間の長さを表すために、
なぜ 60 進数が使われているのか?」
についても、
10 進数の場合と同じように理由は定かではないようです。

中には、
「60 という数は、
いろんな数で割り切れる (2、
3、
4、
5、
6、
10、
12、
15、
30 のすべてで割り切れる) から」という説もあります。
60 は約数が多いため、
時間を扱う上で便利だから使われるようになった、
というわけです。
#+end_note

#+begin_note
ある小学生の指導書に、
#+begin_quote
小学校一年生の算数のカリキュラムの中で最も難しい (そして苦手な子供が多い) のは「時計を使った時間の計算」です
#+end_quote
という記述がありました。
時計の表記が 12 進法という 10 進法とは異なる概念であるため、
小学生には、
習得がなかなか困難だということでしょう。

これに加えて、
#+begin_quote
時計を使った時間の計算 (12 進法) は最も難しいのですが、
これ以降のカリキュラムでほとんど出てきません。
苦手なら無理にやらせなくてもかまいません。
#+end_quote
といった記述もありました。
日常生活で必要となるのは主に 10 進数であり、
やはりそれ以外の数の概念を理解するのは簡単ではないようです。
#+end_note

アセンブリ言語でプログラムを書くためには、
10 進数だけでなく、
*2 進数 (binary number)* と *16 進数 (hexadecimal number)* にも習熟する必要があります。

以下では、
2 進数や 16 進数も含めた、
コンピュータで一般的に用いられる数の表現を説明します。

** N 進数
<<sec:number/n-number>>

*** N 進数の定義 (整数の場合)

例えば、
10 進数の 1 234 には、
\begin{align}
  & 10^3 \times 1 + 10^2 \times 2 + 10^1 \times 3 + 10^0 \times 4 \notag \\
  = & 1000 + 200 + 30 + 4 \\
  = & 1234
\end{align}
という関係が成り立っています。

同様に、
上で例に挙げた 60 進数 01:23:45 (10 進数: 5 025) には、
\begin{align}
  & 60^2 \times 01 + 60^1 \times 23 + 60^0 \times 45 \notag \\
  = & 3600 + 1380 + 45  \\
  = & 5025
\end{align}
という関係が成り立っています。

これを一般化すると、
*N 進数* を数学的に定義できます。

$m$ 桁の N 進数を、
$a_i \, \in \{ 0, 1, \dots, N- 1\}$ を用いて
\begin{align}
  a_{m-1} \, a_{m-1} \cdots a_2 \, a_0 \posn{N}
\end{align}
と表記します。
これは、
1 桁目の位の数が $a_0$ に、
2 桁目の位の数が $a_1$ に、
$m$ 桁目の位の数が $a_{m-1}$ に対応しており、
右下の「($N$)」は N 進数の値であることを意味しています。
なおこの表記は、
\begin{align}
  a_{m-1} \times a_{m-2} \times \cdots \times a_1 \times a_0
\end{align}
のような数の積 (乗算の結果) を意味しているのでは *なく*、
単に、
$a_{m-1}$ から $a_0$ までを並べて表したものを意味していることに注意しましょう。
つまり、
ここでは $a_0$ から $a_{m-1}$ まで $m$ 個の値があるので、
これは $m$ 桁の数だというわけです。

そしてこのとき、
以下の関係が成り立ちます。
\begin{align}
  \lefteqn{a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \posn{N}} \\
  & = N^{m-1} a_{m-1} + N^{m-2} a_{m-2} + \ldots + N^1 a_1 + N^0 a_0 \\
  & = \sum_{i = 0}^{m-1} N^i a_i
\end{align}

実際に、
10 進数の 1234 や 60 進数の 01:23:45 について確かめると、
表 [[tab:number/1234]] や表 [[tab:number/01-23-45]] のようになります。

#+caption: 10 進数の 1 234
#+label: tab:number/1234
| 桁の番号 $i$    |             3 |   |             2 |   |             1 |   |             0 |        |      |
|-----------------+---------------+---+---------------+---+---------------+---+---------------+--------+------|
| 桁 $i$ の大きさ |          10^3 |   |          10^2 |   |          10^1 |   |          10^0 |        |      |
| 位 $i$ の数     |             1 |   |             2 |   |             3 |   |             4 |        |      |
|                 | 10^3 \times 1 | + | 10^2 \times 2 | + | 10^1 \times 3 | + | 10^0 \times 4 |        |      |
|                 |          1000 | + |           200 | + |            30 | + |             4 | \equal | 1234 |

#+caption: 60 進数の 01:23:45 (= 5 025)
#+label: tab:number/01-23-45
| 桁の番号 $i$    |              2 |   |              1 |   |              0 |        |      |
|-----------------+----------------+---+----------------+---+----------------+--------+------|
| 桁 $i$ の大きさ |    60^2 (時間) |   |      60^1 (分) |   |      60^0 (秒) |        |      |
| 位 $i$ の数     |             01 |   |             23 |   |             45 |        |      |
|                 | 60^2 \times 01 | + | 60^1 \times 23 | + | 60^0 \times 45 |        |      |
|                 |           3600 | + |           1380 | + |             45 | \equal | 5025 |

*** N 進数の定義 (実数の場合)

上の例は正の整数の場合ですが、
同じように正の実数の場合も定義することができます。

$i$ 桁目の値が $a_i$ である $N$ 進数を
\begin{align}
  a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \, . \, a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{N}
\end{align}
と表記します。
$a_0$ と $a_{-1}$ の間のピリオド (~.~) は小数点を意味しており、
例えば、
小数点以下第 1 位の数は $a_{-1}$ に、
小数点以下第 2 位の数は $a_{-2}$ に対応します。
また、
$m$ 桁の整数部と $l$ 桁の小数部があることから、
これは $m + l$ 桁の数だといえます。

このとき、
整数の場合と同じように、
以下の関係が成り立ちます。
\begin{align}
  \lefteqn{a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \, . \, a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{N}} \\
  & = N^{m-1} a_{m-1} + \ldots + N^0 a_0 + N^{-1} a_{-1} + \ldots + N^{-l} a_{-l} \\
  & = \sum_{i = -l}^{m-1} N^i a_i
\end{align}

簡単な例で確認してみましょう。
例えば、
10 進数の 123.45 であれば、
\begin{align}
  & 10^2 \times 1 + 10^1 \times 2 + 10^0 \times 3 + 10^{-1} \times 4 + 10^{-5} \times 5 \notag \\
  & 100 + 20 + 30 + 0.4 + 0.05 \\
  & = 123.45
\end{align}
という関係が確かに成り立っていることがわかります (表 [[tab:number/1234.45]])。

#+caption: 10 進数の 123.45
#+label: tab:number/1234.45
| 桁の番号 $i$    |             2 |   |             1 |   |             0 |   |               -1 |   |               -2 |        |        |
|-----------------+---------------+---+---------------+---+---------------+---+------------------+---+------------------+--------+--------|
| 桁 $i$ の大きさ |          10^2 |   |          10^1 |   |          10^0 |   |          10^{-1} |   |          10^{-2} |        |        |
| 位 $i$ の数     |             1 |   |             2 |   |             3 |   |                4 |   |                5 |        |        |
|                 | 10^2 \times 1 | + | 10^1 \times 2 | + | 10^0 \times 3 | + | 10^{-1} \times 4 | + | 10^{-2} \times 5 |        |        |
|                 |           100 | + |            20 | + |             3 | + |              0.4 | + |             0.05 | \equal | 123.45 |

*** 人工的な例 (5 進数)

ここからは、
$N$ 進数という考え方にさらに慣れるために、
人工的な例として、
5 進数について考えましょう。
5 進数は、
各桁を 0〜4 (0、
1、
2、
3、
4 の 5 種類) の文字で表す数です。

それでは例として、
5 進数の 214\posn{5} を考えます。
なお、
214\posn{5} の右下にある (5) は、
この数が 5 進数であることを意味しています。

#+begin_note
214\posn{5} という数字の並びを見ると、
「にひゃく・じゅう・よん」と読みたくなります。
しかし、
「にひゃく・じゅう・よん」は 10 進法での読みであり、
5 進数として読むなら「に・いち・よん」と読むことになるでしょう。
#+end_note

5 進数の 214\posn{5} を 10 進数に変換するには、
\begin{align}
  5^2 \times 2 + 5^1 \times 1 + 5^0 \times 4 = 59
\end{align}
のように計算します (表 [[tab:number/5-214]])。

#+caption: 5 進数の 214
#+label: tab:number/5-214
| 桁の番号 $i$     |            2 |   |            1 |   |            0 |        |    |
|------------------+--------------+---+--------------+---+--------------+--------+----|
| $i$ 桁目の大きさ |          5^2 |   |          5^1 |   |          5^0 |        |    |
| $i$ 桁目の位の数 |            2 |   |            1 |   |            4 |        |    |
| 合計             | 5^2 \times 2 | + | 5^1 \times 1 | + | 5^0 \times 4 |        |    |
| \equal           |           50 | + |            5 | + |            4 | \equal | 59 |


同じように、
5 進数の実数 214.03\posn{5} を考えます。
5 進数の 214.03\posn{5} を 10 進数に変換するには、
\begin{align}
  5^2 \times 2 + 5^1 \times 1 + 5^0 \times 4 + 5^{-1} \times 0 + 5^{-2} \times 3 = 59.12
\end{align}
のように計算します。

#+begin_note
これも、
10 進数として「にひゃく・じゅう・よん・てん・ゼロ・さん」と読みたくなります。
しかし、
5 進数として読むなら、
「に・いち・よん・てん・ゼロ・さん」と読むことになるでしょう。
#+end_note

*** N 進数の表記法

N 進数の各桁は 0〜9 のようなアラビア数字 (Arabic numerals) で表すのが一般的ですが、
N が 10 を超える場合は 0〜9 では文字が足りません。
N 進数を表記するためには各桁に N 種類の文字が必要になるため、
例えば後ほど説明する 16 進数では、
アラビア数字の 0〜9 に、
アルファベットの A〜F (もしくは a〜f) を加えた 16 文字を使用します。

#+begin_note
とはいえ、
必ずしもアラビア数字やアルファベットで表さなければならない、
というわけでもありません。
上の例で示した 5 進数の場合、
例えば 0〜4 を、
ひらがなの「あ」〜「お」等に割り当ててもかまいません (表 [[tab:number/5-ex]])。
N 進数という考え方と、
N 進数の各桁を何で表記するかはまた別の話だからです。
各桁を 0〜4 で表記しても 5 進数ですし、
各桁を「あ」〜「お」で表記しても 5 進数です。

例えば、
各桁を「あ」〜「お」で表記すると 5 進数の 214 は「ういお」になり、
同様に、
5 進数の 214.03 は「ういお .あえ」になります。
これはこれでナゾナゾみたいで面白いですね。
#+end_note

#+caption: 0〜5 と「あ」〜「お」の対応の例
#+label: tab:number/5-ex
| 数 | 桁の表記 |
|----+----------|
|  0 | あ       |
|  1 | い       |
|  2 | う       |
|  3 | え       |
|  4 | お       |

** 2 進数 (整数)
<<sec:number/binary>>

では、
コンピュータで使われる具体的な N 進数として、
2 進数の説明から始めましょう。
[[sec:number/n-number]] 節で述べたように、
整数も実数も N 進数として表現できますが、
コンピュータでは主に整数が用いられるので、
まずは整数の場合に話を限定します。
実数の表現については後ほど [[sec:number/binary-real]] 節で説明します。

*** 非負整数の場合

コンピュータが扱う数は、
基本的にすべて *2 進数 (binary number)* です。
例外もありますが、
通常、
*デジタル回路 (digital circuit)* で構成されたコンピュータは、
数を 2 進数で表現し、
格納し、
演算します。

具体的にはどういうことか、
非負整数 (0 以上の整数) の場合を例に説明していきます。

2 進数とは、
各桁が 0 または 1 で表される数であり、
例えば 101\posn{2} や 01111010\posn{2} のような数です。
5 進数の場合と同様、
右下の (2) は、
これらの値が 2 進数であることを意味しています。

先ほどの定義より、
2 進数の 101\posn{2} は
\begin{align}
  2^2 \times 1 + 2^1 \times 0 + 2^1 \times 0 = 5
\end{align}
であることがわかります。
つまり、
2 進数の 101\posn{2} は 10 進数の 5 というわけです。

同様に、
2 進数の 01111010\posn{2} は
\begin{align}
  2^7 \times 0 + 2^6 \times 1 + 2^5 \times 1 + 2^4 \times 1 & + 2^3 \times 1 + 2^2 \times 0 + 2^1 \times 1 + 2^0 \times 0 = 122
\end{align}
であることがわかります。
つまり、
2 進数の 01111010\posn{2} は 10 進数の 122 です。

*** コンピュータが 2 進数を使う理由

人間が 10 進数や 60 進数を使っている理由が明確ではないのとは対照的に、
コンピュータが 2 進数を使う理由は明確です。

一般のデジタル回路は、
電圧の高 (high) と低 (low) で 1 と 0 を表現します。
例えば、
5 V (volt) で正論理 (positive logic) のデジタル回路であれば、
5 V が 1 を、
0 V が 0 を表します。
また、
3.3 V で負論理 (negative logic) のデジタル回路であれば、
0 V が 1 を、
3.3 V が 0 を表します。

このように、
通常のデジタル回路は 1 と 0 の 2 値 (binary) を扱います。
したがって、
デジタル回路で構成されるコンピュータが扱う数は、
1 と 0 の 2 値を用いた 2 進数で表現されます。

*** 「ビット」と「バイト」の由来

コンピュータにおける最小の情報の単位は *ビット (bit)* と呼ばれます。
なお、
ビットという名前は、
2 値数 (Binary digIT) から来ているそうです。

ビットは、
0 と 1 の 2 通りを表現できます。
また、
いくつかのビットを並べた、
ビットの列によって 2 進数を表現します。
例えば、
2 進数の 01111010\posn{2} は 8 個のビットの列です。

ビットは非常に小さな情報の単位です。
人間にとってはそのままでは (単位が小さすぎて) 扱うのが面倒です。
このため、
8 個のビットをまとめた情報の単位である *バイト (byte)* が広く用いられています。
もちろん、
4 個のビットをまとめた単位でもよかったはずですし、
12 個のビットをまとめた単位でもよかったはずですが歴史的に、
8 個のビットをまとめた情報の単位であるバイトが広く使われています。

#+caption: 情報の単位 (ビット、ニブル、バイト、ワード、ダブルワード)
#+label: fig:number/byte
#+attr_latex: :width \columnwidth
[[./figure/number/byte.png]]

#+begin_note
*バイト (byte)* の名付け親は Werner Buchholz 氏です。
Buchholz 氏の記録を読むと、
「8 ビット = 1 バイト」とした理由は、
- すべての英数字を表現するのに少なくとも 7 ビット必要
- 2 のべき乗の値が望ましい
ということだったようです。
つまり、
「7 ビット以上で、
2 のべき乗のもの」という理由で 8 ビットが選ばれたようです。

バイトという名前の由来についても説明がありました。
当初は、
複数の bit を (コンピュータが同時に扱う単位で) まとめたものを「bite」と呼んでいたそうです。
しかし、
bit と bite が区別しづらいという問題があったため、
「bite (英語の発音は「バイト」) と同じ発音で別のつづりの語である byte を考案した」のだそうです。
#+end_note

ただ、
ややこしいことに、
必ずしも「8 ビット = 1 バイト」とは限りません。
ほとんどのコンピュータでは「8 ビット = 1 バイト」ですが、
一部のコンピュータではては「6 ビット = 1 バイト」だったり、
「9 ビット = 1 バイト」だったりします。
「8 ビット = 1 バイト」というのはあくまで慣例であることに注意が必要です。

#+begin_note
コンピュータサイエンス分野ではバイトを使います。
一方、
情報通信分野では、
バイトの代わりに *オクテット (octet)* を使います。
オクテットは、
8 個のビットをまとめた情報の単位です。
つまり、
- 1 バイト = 普通は 8 ビット (ただし例外あり)
- 1 オクテット = 必ず 8 ビット
という関係です。

8 ビットを表す単位としては、
バイトよりもオクテットのほうがよい名前だと思いますが、
(少なくとも今のところは) バイトのほうが広く使われています。
#+end_note

バイトほど頻繁には使われませんが、
4 ビットをまとめた情報の単位である *ニブル (nibble)* もときどき使われます。
1 バイト (8 ビット) は 2 ニブルで構成されます。
また、
16 進数の各桁は 4 ビットで表されるので、
16 進数の各桁がそれぞれ 1 ニブルに対応します。

*** 上位ビットと下位ビット

2 進数において、
上位の桁を *上位ビット (high bit)* と呼び、
下位の桁を *下位ビット (low bit)* と呼びます。
図 [[fig:number/bits]] を見ながら、
どちらが上位で、
どちらが下位なのかを正しく覚えておきましょう。
例えば、
2 進数の 01111010\posn{2} においては、
最初の (左端の) 0 が最上位ビットの 0、
最後の (右端の) 0 が最下位ビットの 0 となります。

#+caption: 2 進数の上位ビット/下位ビットと MSB/LSB (8 ビットの場合)
#+label: fig:number/bits
[[./figure/number/bits.png]]

また特に、
*最上位ビット* と *最下位ビット* という言葉はよく使われます。
最上位ビットは *MSB (Most Significant Bit)* とも呼ばれ、
また、
最下位ビットは *LSB (Least Significant Bit)* とも呼ばれるため、
MSB や LSB という表現もよく登場します。
これらもあわせて覚えておきましょう。

*** 2 進数で表現できる値の範囲

$k$ 桁の 2 進数で表現できる非負整数は 0 から $2^k - 1$ です (表 [[tab:number/minmax]])。
この非負整数の最小値は、
各ビットがすべて 0 の場合である 0 です。
また、
最大値は各ビットがすべて 1 の場合である $2^k - 1$ です (表 [[tab:number/minmax]])。

#+caption: $k$ 桁の 2 進数で表現できる非負整数の最大値と最小値
#+label: tab:number/minmax
| ビット数 $k$ | 最小値 | 最大値 ($2^k - 1$) |
|--------------+--------+--------------------|
|            1 |      0 |                  1 |
|            2 |      0 |                  3 |
|            3 |      0 |                  7 |
|            4 |      0 |                 15 |
|            5 |      0 |                 31 |
|            6 |      0 |                 63 |
|            7 |      0 |                127 |
|            8 |      0 |                255 |
|           10 |      0 |              1 023 |
|           16 |      0 |             65 535 |
|           24 |      0 |         16 777 216 |
|           32 |      0 |      4 294 967 295 |

例えば、
$k = 8$ の場合、
8 桁の 2 進数で表現できる非負整数は 0 から 2^8 - 1 (= 255) となります。
なぜこうなるかは、
#+begin_quote
8 桁のビット列で表現できる組み合わせは、
各桁が 0、
1 の 2 通りなので、
全部で 2^8 通りある。
ただし 0 も表現する必要があるので、
結果的に表現できる非負整数の最大値は 2^8 - 1 となる。
#+end_quote
と覚えてもよいでしょう。
もしくは、
#+begin_quote
8 桁の 2 進数で表現できる非負整数の最大値に +1 すると 1 00000000\posn{2} (= $2^8$) になる。
したがって、
表現できる非負整数の最大値が 2^8 - 1 である。
#+end_quote
のように覚えてもよいでしょう。

プログラミング言語では、
2 進数の値は 0b01111010 のように、
先頭に 0b を付けて表記することもあります。
ただし、
2 進数を扱えない (プログラムのコード中に直接 2 進数を書けない) プログラミング言語も多くあります。

*** 2 進数に習熟するには

コンピュータの内部構造を理解するためには、
ある程度 2 進数の取り扱いに慣れておくことが必要です。
少なくとも、
- 2 進数 → 10 進数への変換
- 10 進数 → 2 進数への変換
- 2 進数での加算 (足し算)
- 2 進数での減算 (引き算)
くらいはできるようになっておきましょう。

2 進数 → 10 進数への変換は、
2 進数の定義どおりに計算すれば大丈夫です。

例として、
01111010\posn{2} を 10 進数に変換しましょう。
これは定義に従って、
\begin{align}
  & 2^7 \times 0 + 2^6 \times 1 + 2^5 \times 1 + 2^4 \times 1 + 2^3 \times 1
  + 2^2 \times 0 + 2^1 \times 1 + 2^0 \times 0 \notag \\
  = & 64 + 32 + 16 + 8 + 2 \\
  = & 122
\end{align}
のように計算できます。

とはいえ、
2^7 や 2^4 等を毎回計算するのは面倒なので、
2 のべき乗の値は (特によく使われるものについては) 暗記しておきましょう (表 [[tab:number/power]])。

#+caption: 2 のべき乗の値
#+label: tab:number/power
#+attr_latex: :align rrl
| 2^k    | 値                         | おおよその値       |
|--------+----------------------------+--------------------|
| 2^0    | 1                          |                    |
| 2^1    | 2                          |                    |
| 2^2    | 4                          |                    |
| 2^3    | 8                          |                    |
| 2^4    | 16                         |                    |
| 2^5    | 32                         |                    |
| 2^6    | 64                         |                    |
| 2^7    | 128                        |                    |
| 2^8    | 256                        |                    |
| 2^9    | 512                        |                    |
| 2^{10} | 1 024                      | 約 1 000           |
| 2^{11} | 2 048                      |                    |
| 2^{12} | 4 096                      |                    |
| 2^{13} | 8 192                      |                    |
| 2^{14} | 16 384                     |                    |
| 2^{15} | 32 768                     |                    |
| 2^{16} | 65 536                     |                    |
| 2^{20} | 1 048 576                  | 約 100万           |
| 2^{24} | 16 777 216                 | 約 1 700万         |
| 2^{30} | 1 073 741 824              | 約 11 億           |
| 2^{32} | 4 294 967 296              | 約 43億            |
| 2^{64} | 18 446 744 073 709 551 616 | 約 1.8京 = 1 800兆 |

表 [[tab:number/power]] に挙げた値のうち、
2^0〜2^{10} は頻繁に使用します。
特に 2^{10} が約 1 000 であることは覚えやすく、
またさまざまな場面で役立ちます。

一方、
2^{24}、
2^{32}、
2^{64} などは、
必ずしも値を正確に覚えておく必要はありません。
しかし、
これらの値も頻繁に使うため、
おおよその大きさは覚えておくとよいでしょう。

これらが頭に入っていれば、
2 進数から 10 進数への変換は簡単です。
例として、
先ほどの 2 進数 01111010\posn{2} を考えましょう。
0 の桁は加算しなくてよいことから、
\begin{align}
  64 + 32 + 16 + 8 + 2 = 122
\end{align}
のように簡単に計算できます。
この程度であれば暗算でも大丈夫でしょう。

10 進数→ 2 進数への変換は、
2 のべき乗の値を、
大きな値から順番に引いて (減算して) いけば計算できます。
減算できれば 1 を、
減算できなければ 0 を書いていきます。
例えば、
122 を 2 進数に変換するには、
| 1. | 122 | から | 2^7 (= 128) を | 引けないので | 0 を書く、 | 残り | 122 |
| 2. | 122 | から | 2^6 (= 64) を  | 引けるので   | 1 を書く、 | 残り |  58 |
| 3. |  58 | から | 2^5 (= 32) を  | 引けるので   | 1 を書く、 | 残り |  26 |
| 4. |  26 | から | 2^4 (= 16) を  | 引けるので   | 1 を書く、 | 残り |  10 |
| 5. |  10 | から | 2^3 (= 8) を   | 引けるので   | 1 を書く、 | 残り |   2 |
| 6. |   2 | から | 2^2 (= 4) を   | 引けないので | 0 を書く、 | 残り |   2 |
| 7. |   2 | から | 2^1 (= 2) を   | 引けるので   | 1 を書く、 | 残り |   0 |
| 8. |   0 | から | 2^0 (= 1) を   | 引けないので | 0 を書く、 | 残り |   0 |
のように計算します。
そうして書き出した数字を並べれば、
01111010\posn{2} が得られます (表 [[tab:number/dec-to-bin]])。

#+caption: 10 進数から 2 進数への変換の例 (122\posn{10} → 01111010\posn{2})
#+label: tab:number/dec-to-bin
| 残り |   | 2のべき乗 |   |    | 引けたか? | 記録する数 |     |
|------+---+-----------+---+----+-----------+------------+-----|
|  122 | - |       128 |   |    | ×        |          0 | MSB |
|  122 | - |        64 | = | 58 | ○        |          1 |     |
|   58 | - |        32 | = | 26 | ○        |          1 |     |
|   26 | - |        16 | = | 10 | ○        |          1 |     |
|   10 | - |         8 | = |  2 | ○        |          1 |     |
|    2 | - |         4 |   |    | ×        |          0 |     |
|    2 | - |         2 | = |  0 | ○        |          1 |     |
|    0 | - |         1 |   |    | ×        |          0 | LSB |

*** 筆算による 2 進数の加算・減算

2 進数での加算・減算は、
10 進数での加算・減算と同じように筆算で求められます。
しばらく慣れるまでに時間がかかるかもしれませんが、
2 進数の筆算であっても、
10 進数の筆算と考え方は同じです。

例として、
2 進数の 0101\posn{2} (= 5) と 0110\posn{2} (= 6) の和を計算してみましょう。

始めに、
10 進数の筆算と同様に 2 つの数を、
桁をそろえて縦に並べます。
#+begin_src raw
  0101
+ 0110
───

#+end_src

そして、
最下位の桁から順番に足していきます。

まず、
1\posn{2} + 0\posn{2} = 1\posn{2} なので、
1 桁目 (最下段の右端) に 1 を記入します。
#+begin_src raw
  0101
+ 0110
───
     1
#+end_src

次に、
2 桁目を計算します。
0\posn{2} + 1\posn{2} = 1\posn{2} なので、
2 桁目に 1 を記入します。
#+begin_src raw
  0101
+ 0110
───
    11
#+end_src

次に、
3 桁目を計算しますが、
ここで繰り上がりが起こります。

2 進数では、
1\posn{2} + 1\posn{2} = 10\posn{2} なので、
3 桁目に 0 を記入します。
さらに、
繰り上がりがあるので、
4 桁目の一番上に 1 を記入します。
#+begin_src raw
  1
  0101
+ 0110
───
   011
#+end_src

最後に 4 桁目を計算します。

1\posn{2} + 0\posn{2} + 0\posn{2} = 1\posn{2} なので、
4 桁目に 1 を記入して、
計算完了です。
#+begin_src raw
  1
  0101
+ 0110
───
  1011
#+end_src

このような計算により、
正しく 0101\posn{2} (= 5) と 0110\posn{2} (= 6) の和である 1011\posn{2} (= 11) が得られます。

減算も加算と同様に筆算で計算できます。
本当に筆算できるか、
実際に計算して試してみるとよいでしょう。

さらに余裕があれば、
- 2 進数どうしの乗算 (かけ算)
- 2 進数どうしの除算 (割り算)
も筆算でできると完璧です。

ただ、
2 進数の乗算や除算は、
加算や減算ほど利用する機会はありません。
2 進数の乗算や除算の低レベルな (「程度が低い」という意味ではなく「原始的な」という意味です) プログラムを自分で書くのでなければ、
できなくてもかまわないでしょう。

*** 負の整数の場合 (2 の補数表現)

これまで説明したように、
非負整数を 2 進数で表現する場合には、
完全に 2 進数の定義どおりです。
つまり、
2 進数における各桁を 0 または 1 で表記します。

一方、
*負の整数 (0 より小さい整数)* を 2 進数で表現するのは、
いくつかの方法があります。
まず、
最も素朴な方法は、
10 進数の場合と同じように符号を付ける値を (「符号」と「量」で表現する) という方法です (図 [[fig:number/neg]])。

#+caption: 負の整数を「符号」と「量」で表現する方法
#+label: fig:number/neg
#+attr_latex: :width .7\columnwidth
[[./figure/number/neg.png]]

例えば、
10 進数の 123 は 2 進数で 1111011\posn{2} ですが、
負数である 10 進数の -123 は *先頭に符号を付けて* -1111011\posn{2} と表記するというわけです。
この方法を用いると、
10 進数の場合と同様に、
先頭の符号を見れば値の正負をすぐに判定できます。
ただし、
コンピュータは + や - といった記号を扱えないので、
符号も含めてすべて 0 と 1 で表現する必要があります。

そこで、
*整数を格納するデータの大きさ* を定めて、
最上位ビットを「符号」とし、
それ以外のビットで「量」を表現するという方法が考えられます。

例えば、
データの大きさを 8 ビットとし、
符号 ~+~ を 0、
符号 ~-~ を 1 と表記すると定めます。
この場合、
10 進数の 123 は 01111011\posn{2} と表現され、
10 進数の -123 は 11111011\posn{2} と表現されます。
これにより、
最上位ビットを見れば値が正か負か (正確には非負か負か) がすぐにわかります。

これはこれでよいのですが、
通常は、
負の整数は以下で説明する *2 の補数 (2's complement)* として表現します。
他にも、
2 の補数表現と似た概念に *1 の補数 (1's complement)* 表現もあります。

2 の補数という名前が堅苦しくて、
何やら難しそうに聞こえますが、
まずは、
2 の補数と 1 の補数の教科書的な説明を見てみましょう。

- *2 の補数*

  正整数 $n \, (> 0)$ の 2 の補数は、
  $n$ の 2 進数の *すべてのビットを反転し*、
  その後に *1 を加えたもの* である。

- *1 の補数*

  正整数 $n \, (> 0)$ の 1 の補数は、
  $n$ の 2 進数の *すべてのビットを反転したもの* である。

この説明を読んで、
何のことかわかるでしょうか?

それぞれの定義を読んで、
書いてあることを理解すること自体は可能でしょう。
また、
定義に従って、
実際に 2 の補数表現や 1 の補数表現を計算することもできると思います。
しかし、
「ああ、
なるほど」という実感は得られないことでしょう。

そこでここからは、
2 の補数が何を意味するのかを説明していきます。

まず簡単な例として、
100 の補数を考えます (図 [[fig:100-compl]]) \cite{Margush16:Some}。
*補数 (complement number)* とは「(ある数) を補う数」という意味であり、
「2 つの数 $n$、
$m$ について、
$m$ が $n$ の 100 の補数である」とは、
\begin{align}
  n + m = 100
\end{align}
が成り立つことを意味します。
$n$ と $m$ の 2 つで 100 なので、
$m$ は *$n$ を補う数* というわけです。
そのため例えば、
12 の 100 の補数は 78 となり、
また、
34 の 100 の補数は 66 となります。
なお $n$ と $m$ がセットなので、
$m$ が $n$ の補数であれば、
$n$ も $m$ の補数となります。

#+caption: 100 の補数
#+label: fig:100-compl
#+attr_latex: :width .7\columnwidth
[[./figure/number/100-compl.png]]

ここで前提として、
「数を 2 桁の 10 進数で表現する (2 桁を超えたら下 2 桁のみ残す)」と決めましょう (図 [[fig:100-compl-neg]])。
この場合、
12 + 34 は桁あふれが起きませんので
\begin{align}
  12 + 34 = 46
\end{align}
になります。
ただし、
56 + 78 は桁あふれが起きて
\begin{align}
  56 + 78 = & 134 → 34 \\
  & 下 2 桁のみ残る
\end{align}
となります。

こうすると、
先ほどの 100 の補数について以下の関係が成り立ちます。
\begin{align}
  n + m = & 100 → 0 \\
  & 下 2 桁のみ残る
\end{align}
$n$ と $m$ の和が 100 なので、
桁あふれによって下位 2 桁が残り 0 になります。
すると、
$n$ と $m$ の和が 0 なので、
$m$ は $-n$ と同じ意味を持つことになります。
つまり、
数を 2 桁の 10 進数で表現する場合は、
$n$ の 100 の補数である $m$ は $-n$ と同じ役割を持つのです。

#+caption: 数を 2 桁の 10 進数で表現する (2 桁を超えたら下 2 桁のみ残す)
#+label: fig:100-compl-neg
#+attr_latex: :width .7\columnwidth
[[./figure/number/100-compl-neg.png]]

例えば、
12 の「100 の補数」は 78 のため、
78 はつまり -12 と同じ意味を持つというわけです。
これは、
\begin{align}
  12 + 78 = & 100 → 0 \\
  & 下 2 桁のみ残る
\end{align}
であることからもわかります。
「$n$ にある数を足して 0 になるなら、
その数 $-n$ である」からです。

さてここで、
2 の補数と 1 の補数の説明に話を戻しましょう。
2 の補数は、
正確には *$2^k$ の補数* を意味します (図 [[fig:2-compl]])。
ここで $k$ は、
整数を格納するデータの大きさを表すビット数です。

#+caption: 2 の補数と 1 の補数 (データの大きさが 8 ビットの場合)
#+label: fig:2-compl
#+attr_latex: :width \columnwidth
[[./figure/number/2-compl.png]]

データの大きさを 8 ビット ($k = 8$) とすると、
$n$ の 2 の補数とは *2^8 の補数* を意味します。
したがって、
例えば 12 の 2 の補数は
\begin{align}
  2^8 - 12 = 244
\end{align}
です。
2 進数で表記すると
\begin{align}
  100000000\posn{2} - 00001100\posn{2} = 11110111\posn{2}
\end{align}
となります。

同じように、
$n$ の 1 の補数とは、
*すべてのビットが 1 である $k$ 桁の 2 進数 (111\dots111\posn{2} = $2^k - 1$) の補数* のことです。
上と同じようにデータの大きさを 8 ビット ($k = 8$) とすると、
12 の 1 の補数は
\begin{align}
  2^8 - 1 - 12 = 243
\end{align}
です。
これをすべて 2 進数で表記すると
\begin{align}
  11111111\posn{2} - 00001100\posn{2} = 11110011\posn{2}
\end{align}
となります。
数 $n$ の 1 の補数を $m_1$ と表記すると、
1 の補数の定義より
\begin{align}
  n + m_1 = 
  \begin{matrix}
    \underbrace{111\dots111\posn{2}} \\
    k 桁
  \end{matrix}
\end{align}
が成り立つため、
「$n$ の 2 進数のすべてのビットを反転すると $m_1$ になる」という関係が成り立ちます。

上の例で、
12 の 1 の補数は 243 でしたが、
それぞれの 2 進数を縦に並べて見てみると
\begin{align}
  12  = & 00001100\posn{2} \\
  243 = & 11110011\posn{2}
\end{align}
のように、
確かにすべてのビットが反転していることがわかります。

同様に、
数 $n$ の 2 の補数を $m_2$ と表記すると、
2 の補数の定義より
\begin{align}
  n + m_2 =   
  \begin{matrix}
    \underbrace{1000\dots000\posn{2}} \\
    k + 1 桁
  \end{matrix}
\end{align}
が成り立ちます。
ここで両辺から 1 を引くと、
\begin{align}
  n + m_2 - 1 = 
  \begin{matrix}
    \underbrace{111\dots111\posn{2}} \\
    k  桁
  \end{matrix}
\end{align}
であることがわかります。
1 の補数の式と見比べると
\begin{align}
  m_1 = m_2 - 1
\end{align}
であることがわかります。つまり
\begin{align}
  m_2 = m_1 + 1
\end{align}
という関係が成り立っています。
1 の補数 $m_1$ に 1 を加えると 2 の補数 $m_2$ になります。

以上を踏まえると、
- $n$ の 2 進数表現のすべてのビットを反転すると 1 の補数 $m_1$ になる
- 1 の補数 $m_1$ に 1 を加えると 2 の補数 $m_2$ になる
ことがわかります。

ここまでの説明を頭に入れて、
冒頭の 2 の補数と 1 の補数の定義をもう一度見てみましょう。

2 の補数表現では、
最上位ビット (MSB) が符号を表します。
最上位ビットが 1 であれば値が負であり、
最上位ビットが 0 であれば値が非負であることを意味します。
例として、
データの大きさが 4 ビットの場合の 10 進数と 2 進数 (2 の補数表現) の対応を確認しておきましょう (表 [[tab:number/10-to-2]])。

#+caption: 10 進数と 2 進数 (2 の補数表現) の対応 (データの大きさが 4 ビットの場合)
#+label: tab:number/10-to-2
| 10 進数 | 2 進数 (2 の補数表現) | 10 進数 | 2 進数 (2 の補数表現) |
|---------+-----------------------+---------+-----------------------|
|       7 |                  0111 |      -1 |                  1111 |
|       6 |                  0110 |      -2 |                  1110 |
|       5 |                  0101 |      -3 |                  1101 |
|       4 |                  0100 |      -4 |                  1100 |
|       3 |                  0011 |      -5 |                  1011 |
|       2 |                  0010 |      -6 |                  1010 |
|       1 |                  0001 |      -7 |                  1001 |
|       0 |                  0000 |      -8 |                  1000 |

*** 2 の補数の (美しい) 性質

$k$ 桁の 2 進数 (2 の補数) で表現できる数の最大値と最小値を表 [[ tab:number/2-compl]] に示します。
最小値は、
最上位ビット (符号ビット) が 1 で、
それ以外のビットがすべて 0 である $-2^{k-1}$ です。
最大値は、
最上位ビット (符号ビット) が 0 で、
それ以外のビットがすべて 1 である $2^{k-1} - 1$ です。

#+caption: $k$ 桁の 2 進数 (2 の補数) で表現できる整数の最小値・最大値
#+label: tab:number/2-compl
#+attr_latex: :environment maxtabular
| 桁数 |         最小値 (2 進数) |            最小値 (10進数) |           最大値(2進数) |            最大値 (10進数) |
|------+-------------------------+----------------------------+-------------------------+----------------------------|
|    1 |                       1 |                         -1 |                       0 |                          0 |
|    2 |                      10 |                         -2 |                      01 |                          1 |
|    3 |                     100 |                         -4 |                     011 |                          3 |
|    4 |                    1000 |                         -8 |                    0111 |                          7 |
|    8 |                10000000 |                       -128 |                01111111 |                        127 |
|   16 |       10000000 00000000 |                    -32 768 |       01111111 11111111 |                      32767 |
|   32 | 10000000 \dots 00000000 |             -2 147 483 648 | 01111111 \dots 11111111 |              2 147 483 647 |
|   64 | 10000000 \dots 00000000 | -9 223 372 036 854 775 808 | 01111111 \dots 11111111 | -9 223 372 036 854 775 807 |

例えば、
データの大きさが 8 ビット ($k = 8$) の場合、
8 桁の 2 進数で表現できる整数は -2^7 (= -128) から 2^7 - 1 (= 127) です。
このデータの最小値は、
最上位ビット (符号ビット) が 1 で、
それ以外のビットがすべて 0 である 10000000\posn{2} (= -128) です。
また最大値は、
最上位ビット (符号ビット) が 0 で、
それ以外のビットがすべて 1 である 01111111\posn{2} (= 127) です。

同じように、
1 の補数の最大値および最小値も見ておきましょう (表 [[tab:number/1-compl]])。
最小値はすべてのビットが 1 である $-2^{k-1} - 1$ であり、
最大値は最上位ビット (符号ビット) が 0 で、
それ以外のビットがすべて 1 である $2^{k-1} - 1$ です。
2 の補数とは異なり、
*1 の補数にはゼロが 2 つある* ことがわかります (最上位ビット以外がすべて 0 である 000\dots000\posn{2} も 100\dots000\posn{2} もどちらもゼロを表します)。
そのため、
1 の補数では表現できる値の範囲が 2 の補数よりも狭くなっています。

#+caption: $k$ 桁の 2 進数 (1 の補数表現) で表現できる整数の最小値・最大値
#+label: tab:number/1-compl
#+attr_latex: :environment maxtabular
| 桁数 |         最小値 (2 進数) |            最小値 (10進数) |          最大値 (2進数) |            最大値 (10進数) |
|------+-------------------------+----------------------------+-------------------------+----------------------------|
|    1 |                       1 |                          0 |                       0 |                          0 |
|    2 |                      11 |                         -1 |                      01 |                          1 |
|    3 |                     111 |                         -3 |                     011 |                          3 |
|    4 |                    1111 |                         -7 |                    0111 |                          7 |
|    8 |                11111111 |                       -127 |                01111111 |                        127 |
|   16 |       11111111 11111111 |                    -32 767 |       01111111 11111111 |                      32767 |
|   32 | 11111111 \dots 11111111 |             -2 147 483 647 | 01111111 \dots 11111111 |              2 147 483 647 |
|   64 | 11111111 \dots 11111111 | -9 223 372 036 854 775 807 | 01111111 \dots 11111111 | -9 223 372 036 854 775 807 |

なお、
2 進数のビット列だけを見ても、
その 2 進数が *符号なし整数 (unsigned integer)* なのか *符号付き整数 (signed integer)* なのかは *判別できない* ことに注意しましょう。
例えば、
2 進数の 10000110\posn{2} は、
符号なし整数として解釈すれば 134 (= 128 + 4 + 2) です。
一方、
2 の補数表現による符号付き整数として解釈すれば -122 です。

#+begin_note
2 進数の 10000110\posn{2} が、
2 の補数で表現された符号付き整数であることがわかっているとします。
この値が 10 進数でいくつかはどうすればわかるでしょうか?

素朴な方法は 2 の補数の求め方の手順を逆にたどるという方法です。
つまり、
$n$ の 2 の補数は
1. $n$ のすべてのビットを反転する
2. その結果に 1 を加える
ことで求められるのでした。
この操作を逆に行えば、
2 の補数から元の非負整数 $n$ が求まります。
つまり、
1. まず 2 の補数から 1 を引く
2. その結果のすべてのビットを反転する
という方法です。
実際に計算してみましょう。
1. 10000110\posn{2} から 1 を引くと 10000101\posn{2}
2. 10000101\posn{2} のすべてのビットを反転すると 01111010\posn{2}
3. これを 10 進数に変換すると $n$ = 64 + 32 + 16 + 8 + 2 = 122 がわかる
4. したがって、10000110\posn{2} は -122

これはこれで正しいのですが、
毎回こういう計算をするのは面倒です。
そこで、
#+begin_quote
2 の補数は $2^k$ の補数である
#+end_quote
ことを思い出せば、
さらに簡単に計算する方法として、
$2^k$ から 2 の補数を引けばよいことがわかります。

これも実際に計算してみましょう。
1. 2^8 から 10000110\posn{2} を引くと 256 - 134 = 122
2. したがって、10000110\posn{2} は -122
確かに、こちらのほうがずいぶん簡単です。
#+end_note

2 の補数を求めるためだけに、
「すべてのビットを反転し、
その後に 1 を加える」というのは非常に面倒で、
使いづらそうです。

しかし、
2 の補数には、
非常に強力で美しい性質があります。
それは、
「2 の補数によって *減算が加算になる*」という性質です。

例えば、
10 進数の 123 - 56 を 2 進数で計算する場合を考えます。
ここでは、
データの大きさを 8 ビットとします。
このとき、
123 は 2 進数で 01111011\posn{2} になります。
また同様に、
56 は 2 進数で 00111000\posn{2} です。
前述のように、
123 - 56 を計算するには、
01111011\posn{2} - 00111000\posn{2} を筆算で計算するというのが 1 つの方法です。

しかし、
ここで 123 - 56 を計算するのではなく、
123 + (-56) の計算を考えてみます。
-56 の 2 の補数表現は 11001000\posn{2} のため、
\begin{align}
123 + (-56) & = 01111011\posn{2} + 11001000\posn{2} \\
            & = 101000011\posn{2} (= 323)
\end{align}
のように計算できます。

計算結果を見ると、
123 + (-56) = 323 という結果になっていて、
まったく意味のない計算のように思えます。
しかし、
最初に「データの大きさを 8 ビットとする」と決めました。
計算結果が 8 ビットに収まらない場合に、
あふれた桁を単純に捨てることにします。
すると、
1 01000011\posn{2} の下位 8 ビットは
\begin{align}
01000011\posn{2} = 67
\end{align}
になります。
確かに 123 + (-56) = 67 が成立しています !

このように、
負の整数を 2 の補数で表現しておけば、
*加算と減算を区別する必要がなくなる* ので、
加算と減算を、
どちらも加算だけで実現できるようになります。
これにより、
コンピュータのハードウェアが簡単 (専用の減算回路が不要) に、
プログラミングも簡単 (プログラム中で値の正負による場合分けが不要) になります。

もちろん、
負の整数を表すのには 2 の補数表現を使わずに、
「符号 + 量」でも、
1 の補数表現でもかまいません。
しかし、
2 の補数表現が強力であるために、
ほとんどのコンピュータは負の整数を 2 の補数で表しています。
実際に、
2 の補数表現を使っていない (かつ現在も利用され続けている) コンピュータを探すのが難しいくらいです。

*** 2 の補数によって減算が加算になる理由

それではなぜ 2 の補数表現を使えば減算が加算になるのでしょうか?

これは、
データの大きさが $k$ の場合、
#+begin_quote
$2^k - n$ を加えることと、
$n$ を引くことが同じ意味を持つ
#+end_quote
からです。

上で説明したように、
2 の補数とは「$2^k$ の補数」を意味します。
したがって、
#+begin_quote
$2^k - n$ ($n$ の 2 の補数) を加えることと、
$n$ を引くことが同じ意味を持つ
#+end_quote
のです。

例えば、
データの大きさが 8 の場合、
2^8 -1 (= 255) を加えることと、
1 を引くことが同じ意味を持ち、
また、
2^8 -1 (= 255) は 1 の「2 の補数」です。

実際に、
123 + 255 を計算すると、
#+begin_src raw
  01111011 (= 123)
+ 11111111 (= 255)
─────
 101111010 (= 378)
#+end_src
となります。
そして、
1 01111010\posn{2} の下位 8 ビットを取り出せば 122 となっており、
確かに 123 - 1 と一致しています。

ある数の下位 8 ビットを取り出すということは、
2^8 (= 256) で割った余りを求めることと同じです。
このため、
\begin{align}
  123 + 255 \equiv 122 \quad (\mbox{mod} \,\, 256)
\end{align}
という関係が成り立つのです (ここで \equiv は 256 を法とする合同を表します)。

** 16 進数
<<sec:number/hexadecimal>>

*** 16 進数の表記法

前述のように、
人間にとってビットは情報の単位としては小さすぎます。
単位として小さすぎるため取り扱いが面倒であり、
ビットの代わりにバイトが広く用いられています。

同じ理由で、
人間にとっては、
2 進数は桁が多すぎて取り扱いが面倒です。
例えば、
10 進数の 1 234 567 890 は、
2 進数では 01001001 10010110 00000010 11010010\posn{2} です。
これだけ桁の多い 2 進数をじーっと見つめていると目がチカチカしますし、
これだけ桁の多い 2 進数を間違えずに入力するのも大変です。
そのため、
多くのプログラミング言語では、
2 進数の代わりに *16 進数 (hexadecimal number)* が広く用いられています。

16 進数では、
各桁は 0〜15 の値を取り、
10 進数の 10〜15 は、
16 進数ではアルファベットの a〜f もしくは A〜F を用いて表します。
まずは、
表 [[tab:number/hex-char]] を暗記しましょう。

#+caption: 10 進数と 16 進数の対応
#+label: tab:number/hex-char
| 10 進数 | 16 進数 |
|---------+---------|
|       0 |       0 |
|       1 |       1 |
|       2 |       2 |
|       3 |       3 |
|       4 |       4 |
|       5 |       5 |
|       6 |       6 |
|       7 |       7 |
|       8 |       8 |
|       9 |       9 |
|      10 |    a, A |
|      11 |    b, B |
|      12 |    c, C |
|      13 |    d, D |
|      14 |    e, E |
|      15 |    f, F |


コンピュータの世界では 16 進数が頻繁に登場し、
2 進数よりも、
16 進数のほうが圧倒的に多くの場面で利用されています。
「c は 12」、
「f は 15」、
「10 は a」、
「14 は e」など、
瞬時に頭の中で変換できるようにしておきましょう。

例えば、
10 進数の 123 は、
16 進数で 7b\posn{16} です。
プログラミング言語では、
16 進数であることを明記するため、
先頭に 0x を付けて 0x7b や、
末尾に h や H (hexadecimal の h) を付けて 7bh や 7bH などと表記されます。
本書では、
N 進数の表記法と同じ 7b\posn{16} や 0x7b という表記を用います。

*** 2 進数から 16 進数への変換

0〜15 の 16 (= 2^4) 種類の値は、
ちょうど 4 ビットで表現できます。
このため、
2 進数→ 16 進数の変換は非常に簡単です。
2 進数を、
下位から 4 ビットずつに区切って、
それぞれを 16 進数で表記すれば変換できます。

例えば、
10 進数の 1 234 567 890 は、
2 進数で 01001001 10010110 00000010 11010010\posn{2} です。
これを 16 進数に変換してみます。

まず、下位ビットから順に 4 ビットごとに区切ります。
#+begin_quote
0100 1001 1001 0110 0000 0010 1101 0010
#+end_quote
このように、
それぞれの 4 ビットが、
16 進数における各桁に相当します。

それでは、
4 ビットの 2 進数をそれぞれ 16 進数に変換しましょう。
| 2進数  | 0100 | 1001 | 1001 | 0110 | 0000 | 0010 | 1101 | 0010 |
|        |   ↓ |   ↓ |   ↓ |   ↓ |   ↓ |   ↓ | ↓   |   ↓ |
| 16進数 |    4 |    9 |    9 |    6 |    0 |    2 | d    |    2 |
これにより、
4996 02d2\posn{16} が得られます。
簡単ですね。

こうして、
10 進数で 10 桁の 1 234 567 890 を、
16 進数では 8 桁の 4996 02d2\posn{16} と表せます。
当然ながら、
10 進数よりも 16 進数のほうが、
各桁で表現できる数の種類が増えるため、
全体の桁数が小さくなります。

#+begin_note
高校の数学で対数 \log を学んだ方は、
「問: $n$ = 2^{30} の桁数を求めよ。
ただし、
\log_2 = 0.301 として計算せよ。」
のような問題を解いたことを覚えていますか?

ある数 $n$ の桁数を $m$ とすると、
\begin{align}
  m - 1 \le \log_{10} n < m
\end{align}
という関係が成立します。
上の問題は、
この性質を利用して、
\begin{align}
  \log_{10} 2^{30} = 30 \log_10 2 = 9.03
\end{align}
と求められ、
2^{30} の桁数は 10 であることがわかります。

これを一般化すれば、
N 進数の桁数も求められます。
ある数 $n$ を $N$ 進数で表記したときの桁数を $m$ とします。
このとき、
\begin{align}
  m - 1 \le \log_{N} n < m
\end{align}
という関係が成立します。

そのように、
少し計算すれば、
例えば $n$ = 2^{64} は、
- 2 進数で 65 桁
- 10 進数で 20 桁
- 16 進数で 17 桁
であることがわかります。
#+end_note

*** 16 進数に習熟するには

2 進数のときと同じように、
少なくとも、
- 16 進数 → 10 進数への変換
- 10 進数 → 16 進数への変換
- 16 進数での加算 (足し算)
- 16 進数での減算 (引き算)
くらいはできるようになっておきましょう。

16 進数 → 10 進数への変換は、
16 進数の定義どおりに計算すれば大丈夫です。

例として、
16 進数の 3a2e\posn{16} を 10 進数に変換してみます。
a\posn{16} = 10、
e\posn{16} = 14 なので、
定義に従って、
\begin{align}
  16^3 \times 3 + 16^2 \times 10 + 16^1 \times 2 + 16^0 \times 14 = 14984
\end{align}
のように計算します。

10 進数→ 16 進数への変換は、
16 のべき乗の値を大きな値から順番に用いて、
変換したい値を割っていけば変換できます。

例えば、
10 進数の 1234 を 16 進数に変換するには、
#+attr_latex: :environment maxtabular
| 1. | 1234 を 16^3 (= 4 096) で割ると、 | 商は 0、余りは 1234。 | 0 を書く。  | 残り 1234 |
| 2. | 1234 を 16^2 (= 256) で割ると、   | 商は 4、余りは 210。  | 4 を書く。  | 残り 210  |
| 3. | 210 を 16^1 (= 16) で割ると、     | 商は 13、余りは 2。   | 13 を書く。 | 残り 2    |
| 4. | 2 を 16^1 (= 1) で割ると、        | 商は 2、余りは 0。    | 2 を書く。  | 残り 0    |
のように計算します。
書き出した数字を 16 進数で並べると 16 進数の 04d2\posn{16} が得られます。

#+caption: 10 進数→16 進数への変換の例
#+label: tab:number/dec-to-hex
| 残り  |   | 2のべき乗 |   | 商 |  余り |
|-------+---+-----------+---+----+-------|
| 1 234 | / |     4 096 | = |  0 | 1 234 |
| 1 234 | / |       256 | = |  4 |   210 |
| 210   | / |        16 | = | 13 |     2 |
| 2     | / |         1 | = |  2 |     0 |

商である 0, 4, 13, 2 を 16 進数にして順番に並べることで 04d2\posn{16} が得られました。

*** 筆算による 16 進数の加算・減算

16 進数での加算 (足し算)、
16 進数での減算 (引き算) も 10 進数や 2 進数の場合と同じように筆算できます。

例として、
16 進数の 1a3c\posn{16} と 42f1\posn{16} の和を計算してみます。

まず、
2 つの数を、
桁をそろえて縦に並べます。
#+begin_src raw
  1a3c
+ 42f1
───

#+end_src

最下位の桁から順番に足していきます。

c\posn{16} (= 12) + 1\posn{16} = d\posn{16} (= 13) なので、
1 桁目 (最下段の右端) に d を記入します。
#+begin_src raw
  1a3c
+ 42f1
───
     d
#+end_src

次に、
2 桁目を計算します。
ここで繰り上がりが起こります。

3\posn{16} + f\posn{16} = 12\posn{16} (= 18) なので、
2 桁目に 2 を記入します。
さらに、
繰り上がりがあるので、
1 を 3 桁目の一番上に記入します。
#+begin_src raw
   1
  1a3c
+ 42f1
───
    2d
#+end_src

次に、
3 桁目を計算します。
1\posn{16} + a\posn{16} (= 10) + 2 = d\posn{16} (= 13) なので、
3 桁目に d を記入します。
#+begin_src raw
   1
  1a3c
+ 42f1
───
   d2d
#+end_src

最後に 4 桁目を計算します。
1\posn{16} + 4\posn{16} = 5 なので、
4 桁目に 5 を記入します。
#+begin_src raw
   1
  1a3c
+ 42f1
───
  5d2d
#+end_src

これによって、
1a3c\posn{16} (= 6 716) と 42f1\posn{16} (= 17 137) の和である 5d2d\posn{16} (= 23 853) が得られました。

これらに加えて、
- 16 進数 → 2 進数への変換
- 2 進数 → 16 進数への変換
もできるようになっておきましょう。

10 進数、
2 進数、
16 進数の間の相互変換や、
2 進数での加算・減算、
16 進数での加算・減算くらいは、
普段から手計算でできるようになっておくべきです。
もちろん、
手計算が「ものすごく速くできる」必要はありません。
普段、
自分でプログラムを書いたり、
読んだりするときは、
10 進数、
2 進数、
16 進数の相互変換や、
2 進数や 16 進数での計算は、
コンピュータに計算させましょう。
ただし、
2 進数や 16 進数の原理を、
頭と体で理解しておくことが重要です。
2 進数や 16 進数の原理が「身に付いている」と感じられる程度に、
2 進数や 16 進数の変換や計算に慣れ親しんでおいてください。

** 8 進数
<<sec:number/octal>>

2 進数や 16 進数ほどではありませんが、
コンピュータサイエンスの分野では *8 進数 (octal number)* もときどき使われます。

*** 8 進数とは?

8 進数では、
各桁は 0〜7 の値を取ります。
例えば 10 進数の 123 は 8 進数で 173\posn{8} です。
N 進数の定義どおり
\begin{align}
  8^2 \times 1 + 8^1 \times 7 + 8^0 \times 3 = 123
\end{align}
という関係です。

プログラミング言語では、
8 進数であることを明記するため、
先頭に 0 を付けて 0173 や、
先頭に 0o を付けて 0o173 などと表記されることがあります。
本書では、
173\posn{8} や 0o173 という表記を用います。

現在のコンピュータでは、
*ワード (word; 語)* の大きさは 8 ビット、
16 ビット、
32 ビット、
64 ビットなど、
4 の倍数のものが大半です。
一方、
数十年前の黎明期のコンピュータでは、
ワードの大きさは 12 ビット、
18 ビット、
36 ビットなど、
3 の倍数のものが多かったそうです。

このため、
ビット列を、
3 ビット単位で区切って扱うと便利でした。
このため、
当時は 8 進数が広く使われていました。
4 ビットを単位として区切るのであれば、
0〜15 を表現できる 16 進数が便利ですが、
3 ビットを単位として区切るのであれば、
0〜7 を表現できる 8 進数が便利だからです。

#+begin_note
通常、
1 バイトは 8 ビットです。
このため、
現在のコンピュータでは 8 進数は扱いづらい面もあります。
しかし、
データが 3 ビット単位で区切られている場合は、
今でも 8 進数が便利に使えます。

例えば UNIX のファイルシステムでは、
ファイルのアクセス権限を「所有者」、
「グループ」、
「その他」に対して設定できます。
所有者・グループ・その他のそれぞれに対して、
読み出し、
書き込み、
実行の可否を設定できるよう、
3 種類の可否を表す 3 ビットが必要です。
そして、
所有者・グループ・その他という 3 者がそれぞれ 3 ビットを持つため、
合わせて 9 ビットで表現します。

UNIX では、
読み出し、
書き込み、
実行の可否をそれぞれ ~r~、
~w~、
~x~ の文字で表します。
読み出しのみ可であれば ~r--~ 、
読み出しと書き込みが可であれば ~rw-~ 、
読み出しと実行のみ可であれば ~r-x~ のように表記します。
例えば、
所有者が読み書き可能 ~rw-~ で、
グループおよびそれ以外は読み出しのみ ~r--~ が可能な場合、
そのファイルのアクセス権限を ~rw-r--r--~ と表記します。

アクセス権限 ~rw-r--r--~ を 2 進数で表せば 1 10100100\posn{2} です。
これを 8 進数で表せば 644\posn{8} です。
アクセス権限は 3 ビットごとのまとまりなので、
8 進数を使うとうまく表現できるのです。
#+end_note

2 進数や 16 進数ほど出番は多くありませんが、
- 8 進数 → 10 進数への変換
- 10 進数 → 8 進数への変換
くらいはできるようになっておきましょう。

** 2 進数 (実数)
<<sec:number/binary-real>>

ここでは、
これまで説明してきたような整数ではなく、
*実数 (real number)* を 2 進数で表現する方法を説明します。

*** 2 進数 (実数) の定義

N 進数の定義は [[sec:number/n-number]] 節で説明しましたが、
もう一度確認しておきましょう。

非負整数の場合、
$i$ 桁目の値が $a_i \, \in \{ 0, 1, \dots, N - 1\}$ である $N$ 進数を
\begin{align}
  a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \posn{N}
\end{align}
のように表記します。

また、
実数の場合は小数点以下の桁も必要になります。
非負の実数は、
$i$ 桁目の値が $a_i$ である N 進数を
\begin{align}
  a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \, . \, a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{N}
\end{align}
のように表記します。
このとき、
$a_0$ と $a_{-1}$ の間にあるピリオド (~.~) が小数点です。
さらに
\begin{align}
  \lefteqn{a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 . a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{N}} \\
  & = N^{m-1} a_{m-1} + \ldots + N^0 a_0 + N^{-1} a_{-1} + \ldots + N^{-l} a_{-l} \\
  & = \sum_{k = -l}^{m-1} N^k a_k
\end{align}
という関係が成り立ちます。

2 進数の実数も、
基本的に上記の定義どおりです。
つまり、
2 進数の実数を
\begin{align}
  a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \, . \, a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{2}
\end{align}
のように表記します。
2 進数なので、
各桁の $a_i$ は 0 か 1 のどちらかを取ります。
2 進数では $N = 2$ なので、
\begin{align}
  \lefteqn{a_{m-1} \, a_{m-2} \cdots a_1 \, a_0 \, . \, a_{-1} \, a_{-2} \cdots a_{-l+1} \, a_{-l} \posn{2}} \\
  & = 2^{m-1} a_{m-1} + \ldots + 2^0 a_0 + 2^{-1} a_{-1} + \ldots + 2^{-l} a_{-l} \\
  & = \sum_{k = -l}^{m-1} 2^k a_k
\end{align}
という関係が成り立ちます。

#+begin_note
いくつか数式が並んでいますが、
要は「すべて N 進数の場合の定義のとおり」ということです。
数学の素晴らしいところは、
「1 つを理解・定義すれば、
それがあらゆる場合に当てはまる」という点です。
N 進数の定義さえ正確に理解できれば、
2 進数、
10 進数、
8 進数、
16 進数など、
あらゆる「何とか進数」も含めてすべてまとめて理解できてしまいます。
#+end_note

上の定義より、
例えば 2 進数の 101.011\posn{2} は
\begin{align}
  2^2 \times 1 + 2^1 \times 0 + 2^0 \times 1 + 2^{-1} \times 0 + 2^{-2} \times 1 + 2^{-3} \times 1 = 5.375
\end{align}
であることがわかります。

*** より簡単に 2 進数から 10 進数へ変換する方法
<<sec:fast-binary-to-decimal-conversion>>

なお、
実数の 2 進数を手計算で 10 進数に変換する場合、
以下のようにすれば少し計算が楽になります。

「2 進数を 10 進数に変換する」ことと、
「2 進数 $x$ 倍してから 10 進数に変換し、
その後で $1/x$ 倍する」ことは同じです。
このため、
1. 実数の 2 進数を $2^l$ 倍してから 10 進数に変換する
2. そのあとで、10 進数に変換した値を $1/2^l$ 倍する
としても同じ値になります。上の例で示した 2 進数 101.011\posn{2} の場合、
1. 最初に 2^3 (= 8) 倍して 101011\posn{2} とする
2. 101011\posn{2} を 10 進数に変換して 43 を求める
3. 43 を 1/2^3 (= 1/8) 倍して 5.375 を得る
とすることで、
2 進数から 10 進数に (より簡単に) 変換できます。
これは
\begin{align}
  \sum_{k = -l}^{m-1} 2^k a_k  = \frac{1}{N^l} \sum_{k = 0}^{m + l - 1} 2^k a_{k + l}
\end{align}
が成り立つという性質を利用しています。

*** 2 進数 (実数) の丸め誤差

「これで実数の 2 進数も理解できた。
めでたしめでたし。」
となればよいのですが、
実数を扱う場合にはいくつか注意が必要です。
上の例のように、
「実数の 2 進数を 10 進数に変換する」場合には何も問題がないのですが、
逆に、
「実数の 10 進数を 2 進数に変換する」場合にはうまく変換できないケースがあります。

例えば、
10 進数の 5.421 875 を 2 進数に変換してみます。
すると、
\begin{align}
  5.421875 = & 2^2 \times 1 + 2^1 \times 0 + 2^0 \times 1 \notag \\
  & + 2^{-1} \times 0 + 2^{-2} \times 1 + 2^{-3} \times 1 + 2^{-4} \times 0 + 2^{-5} \times 1 + 2^{-6} \times 1
\end{align}
が成り立ちます。
したがって、
10 進数の 5.421 875 は 2 進数で 101.011011\posn{2} です。

次に、
最後の 1 桁だけを変えた、
10 進数の 5.421876 を 2 進数に変換してみます。
すると先ほどとは異なり、
\begin{align}
  5.421876 = & 2^2 \times 1 + 2^1 \times 0 + 2^0 \times 1 \notag \\
  & + 2^{-1} \times 0 + 2^{-2} \times 1 + 2^{-3} \times 1 + 2^{-4} \times 0 \notag \\
  & + 2^{-5} \times 1 + 2^{-6} \times 1 + 2^{-7} \times 0 + 2^{-8} \times 0 + \dots \notag \\
  & + 2^{-19} \times 0 + 2^{-20} \times 1 + 2^{-21} \times 0 + \dots
\end{align}
のようにいつまでも続いてしまいます。
このため、
5.421876 を 2 進数に変換すると、
#+begin_src raw
101.011011000000000000010000110001101111011110100000101101011110110110
0011010011011010110100110001111111001101001001001110000101100000110110
0010000111111010111111001000101100000000011110011010001010000011010011
0100100110111110100011111111001100100111101010100110100011110100101101
1000011111111000100001110110010110111010011011101111110000110111000111...
#+end_src
のようにいつまでも続く 2 進数になります (ここでは小数点以下 1 000 桁まで載せています)。
小数点以下に数が無限に並ぶ、
いわゆる無限小数 (infinite decimal) です。

10 進数で有限桁の 5.421 876 を 2 進数に変換すると無限桁になってしまう、
つまり、
10 進数の 5.421 876 は *有限桁の 2 進数では表現できない* のです。

通常、
コンピュータは 2 進数で表現した数を扱います。
ソフトウェアの作り方にもよりますが、
コンピュータで扱える 2 進数の桁数は 23 桁や 52 桁などのように決まっています。
プログラミング言語でも、
電卓アプリでも、
表計算ソフトウェアでも、
10 進数をコンピュータに入力すると、
通常、
コンピュータは 10 進数を 2 進数に変換します。
それ以降、
すべての演算は 2 進数で行われます。

例えば 10 進数の 5.421 876 をコンピュータに入力するとして、
2 進数の桁数が 52 桁であれば、
#+begin_quote
101.0110110000000000000100001100011011110111101000001\posn{2}
#+end_quote
という 2 進数に変換されます (これ以降の小数点は記録されません)。
そしてこれを再度 10 進数に戻すと、
5.421 876 ではなく *5.42188 になってしまいます*。
つまり、
コンピュータに 10 進数の 5.421 876 を入力した瞬間に、
内部では 5.421 88 という丸められた値になってしまうのです。

このように、
10 進数の実数をコンピュータで扱う場合は、
コンピュータが扱っているのは多くの場合 *正確な値ではなく近似値である* ということに注意しましょう。
10 進数の実数が丸められてしまうという問題は、
プログラミング言語 (C 言語や Java 言語等) やオペレーティングシステム (GNU/ Linux、
Windows、
macOS 等) によって生じている問題ではありません。
すべての計算を 2 進数で行うコンピュータが持っている本質的な制約なのです。

#+begin_note
2 進数の丸め誤差は、
10 進数を 2 進数で扱うことによって発生します。
したがって、
数を 10 進数のまま扱うような特殊なプログラムを書けば、
コンピュータ上で上記のような丸め誤差が起きない計算をすることも可能です。
実際に科学技術計算用のソフトウェアでは、
任意の桁数の精度を保証した演算を実現しているものもあります。
#+end_note

*** 固定小数点表現
<<sec:fixed-point-nubmer>>

ここまで、
実数を 2 進数で表現する方法を説明しました。

コンピュータは、
多くの場合、
数値を保存するために 16 ビット、
32 ビット、
64 ビットなど、
ある一定の大きさの記憶領域を用います。
16 ビットあれば 16 桁の 2 進数を格納でき、
同様に、
32 ビットあれば 32 桁の 2 進数を、
64 ビットあれば 64 型の 2 進数を格納できます。

2 進数に限らず、
一般の N 進数において全体の桁数が決まっている場合、
実数を表現する形式には以下の 2 通りがあります。
- 固定小数点表現 (fixed-point representation)
- 浮動小数点表現 (floating-point representation)

1 つ目の *固定小数点表現 (fixed-point representation)* とは、
文字通り *小数点を固定した* 数値の表現方式です。
全体のビット数のうち、
何ビットを整数部に使い、
何ビットを小数部に使うかをあらかじめ決めておきます。

説明の簡単化のため、
データの大きさが 8 ビットの場合を考えましょう。
例えば、
8 ビットのうち、
上位 4 ビットを整数部に、
下位 4 ビットを小数部に使うと決めたとします。
つまり、
$a_7 a_6 a_5 a_4 a_3 a_2 a_1 a_0 \posn{2}$ を $a_7 a_6 a_5 a_4 . a_3 a_2 a_1 a_0 \posn{2}$ という 2 進数として扱います ($a_4$ と $a_3$ の間の小数点 (~.~) に注意してください)。

この場合、
例えば 10111101\posn{2} という 8 ビットの列は 1011.1101\posn{2} という小数であると見なしますし、
10 進数の 13 (2 進数で 1101\posn{2}) を格納する場合には、
小数部をゼロで埋めて 11010000\posn{2} とします。
つまりこの例は、
「4 ビット目と 5 ビット目の間に小数点があると見なす」方式だといえ、
例えば 00110100\posn{2} は 2 進数の 0011.0100\posn{2} (= 3.25) を意味することになります。

この例では上位 4 ビットが整数部、
下位 4 ビットが小数部でしたが、
固定小数点表現では全体のビット数のうち何ビットを整数部に使い、
何ビットを小数部に使うかは *自由に決めてかまいません*。
実際には、
格納したい値がどのような範囲の値であるかによって決定することになります。

*** 固定小数点表現の利点・欠点

固定小数点表現は、
後述する浮動小数点表現よりも精度の点では劣りますが、
*実現が簡単で、
なおかつ演算が高速* です。
このため、
精度よりも単純さや速度が求められる用途に向いています。

実現が簡単で、
演算が高速である理由は、
固定小数点表現の数値の四則演算が、
*整数演算とビットシフトで実現できる* からです。
いくつか例を使って説明しましょう。

まず、
固定小数点表現の数 0011.1101\posn{2} (= 3.812 5) と 0010.0110\posn{2} (= 2.37 5) を考えます。
固定小数点表現の数の加算は、
*2 つの値を整数と見なしたときの加算と等しく* なります。
つまり、
0011.1101\posn{2} (= 3.812 5) と 0010.0110\posn{2} (= 2.375) を、
それぞれ 00111101\posn{2} (= 61) と 00100110\posn{2} (= 38) と見なして加算するわけです。

これによって得られた 0110011\posn{2} (= 99) を固定小数点表現の値と解釈すれば
6.187 5 になっています。
#+begin_src raw
   0011.1101 (= 3.8125) + 0010.0110 (= 2.375)
         固定小数点表現の数の加算
→ 0011 1101 (= 61)     + 0010 0110 (= 38)    = 0110 0011 (= 99)
       固定小数点表現ではなく、単なる整数と見なして演算する
→                                              0110.0011 (= 6.1875)
                                     演算結果を固定小数点表現として解釈する
#+end_src

減算も同じです。
固定小数点表現の数値を、
どちらも整数と見なして減算するだけです。

乗算の場合も同様に、
固定小数点表現の数値をどちらも整数と見なして乗算します。
ただし、
乗算後に、
*小数点の桁を合わせるために適宜ビットシフト* します。
今の例の場合、
整数部が 4 ビット、
小数部が 4 ビットなので、
乗算後に 4 ビット右にシフトします。
例えば、
0011.1101\posn{2} (= 3.812 5) と 0010.0110\posn{2} (= 2.375) の乗算を、
00111101\posn{2} (= 61) と 00100110\posn{2} (= 38) の乗算として計算します。
これによって得られた 100100001110\posn{2} (= 231 8) を右に 4 ビットシフトします。
ビットシフトした値を、
固定小数点表現の値として解釈すれば 9.0 が得られます。

#+begin_note
3.812 5 と 2.375 の積は 9.054 6875 です。
今の例では、
小数部が 4 ビットしかありませんので、
丸め誤差が発生して結果が 9.0 になっています。
#+end_note

#+begin_src raw
   0011.1101 (= 3.8125) * 0010.0110 (= 2.375)
          固定小数点表現の数の乗算
→ 0011 1101 (= 61)     * 0010 0110 (= 38)    =  1001 0000 1110 (= 2318)
       固定小数点表現ではなく、単なる整数と見なして演算する
→                                               1001.0000      (= 9.0)
                                     演算結果を固定小数点表現として解釈する
                                          (4 ビット右にシフトする)
#+end_src

除算も同様です。
ただし、
除算後に右にビットシフトするのではなく、
*左にビットシフト* します。

このように、
固定小数点表現は理解するのが簡単であり、
基本的に整数演算やビットシフトで実現できるため演算も高速です。
一方、
固定小数点表現の最大の欠点は、
*表現できる値の範囲が狭い* という点です。

先ほどの例に挙げた、
8 ビットの固定小数点表現 (整数部 4 ビット、
小数部 4 ビット) の場合、
表現できる値の (ゼロではない) 最小値は 0000.0001\posn{2} (= 0.062 5) であり、
表現できる値の最大値は 1111.1111\posn{2} (= 15.937 5) です。
このため、
8 ビットで表現できる値の範囲は 0.062 5〜15.937 5 となります。

取り扱う値の範囲が、
この範囲に収まるとあらかじめわかっているのであれば固定小数点表現はよい選択だといえるでしょう。
しかし、
取り扱う値の範囲がこの範囲に収まらないのであれば、
固定小数点表現は使えません。

より現実的な例として、
8 ビットではなく、
32 ビットの固定小数点表現 (データの大きさが 32 ビット) の場合を考えましょう。
このとき、
例えば、
上位 24 ビットを整数部に、
下位 8 ビットを小数部に使うと決めたとします。

このとき、
表現できる値の (ゼロでない) 最小値は 00000000 00000000 00000000.00000001\posn{2} (= 0.003 906 25) であり、
一方、
表現できる値の最大値は 11111111 11111111 11111111.11111111\posn{2} (= 65 535.996 093 75) です。
つまり、
32 ビットで表現できる値の範囲が 0.003 906 25〜65 535.996 093 75 となるわけです。
このくらいの値の範囲があれば、
用途によっては十分だといえるでしょう。

*** 浮動小数点表現
<<sec:floating-point-nubmer>>

先ほど、
より広い範囲の値を表現するために、
32 ビットの固定小数点表現を紹介しました。

しかし、
現実には取り扱う値の範囲がさらに広いことも多いため、
多くのケースで固定小数点表現ではなく、
*小数点の位置を固定しない* 数の表現方式である *浮動小数点表現 (floating-point representation)* が用いられます。
つまり、
値を表現するビットのうち、
どのビットがどの桁を表すかを固定しない方法が用いられます。

浮動小数点表現の基本的な考え方は、
物理や化学などで広く用いられている *科学的記数法 (scientific notation)* と同じです。
科学的記数法は *指数表記 (exponential notation)* とも呼ばれ、
非常に桁数の多い数値を頻繁に扱う物理や化学などの科学技術分野で広く用いられる方法です。

科学的記数法では多くの場合、
*係数 (coefficient)* と *指数 (exponent)* の 2 つを用いて、
*係数 \times 10^{指数}* のような形式で数値の有効桁数を明示します。
例えば、
- 12 300
- 0.004 56
- 602 214 076 000 000 000 000 000 (アボガドロ定数)
のような数を
- 1.23 \times 10^{4}
- 4.56 \times 10^{-3}
- 6.022 140 76 \times 10^{23} (アボガドロ定数)
のように表現します。
つまり、
指数が数の桁数を表し、
係数がその桁数の中でどのくらいの大きさなのかを表すのです。

コンピュータにおける浮動小数点表現は、
*科学的記数法の 2 進数版* と言えます。
[[ sec:fixed-point-nubmer]] 節と同様に、
ここでも説明の簡単化のため、
まずは実数を記憶するデータの大きさが 8 ビットの場合を考えましょう。

そのとき例えば、
8 ビットのうち、
上位 4 ビットを指数部に、
下位 4 ビットを係数部に使うと決めたとします。
つまり、
8 ビットの列 $a_7 a_6 a_5 a_4 a_3 a_2 a_1 a_0\posn{2}$ を $e_3 e_2 e_1 e_0 c_3 c_2 c_1 c_0\posn{2}$ のように使い、
$e_3 e_2 e_1 e_0 \posn{2}$ で指数を、
$c_3 c_2 c_1 c_0 \posn{2}$ で係数を表すことにします。
実際にはいくつかのバリエーションがありますが、
ここでは係数の $c_3 c_2 c_1 c_0 \posn{2}$ は、
整数部が 1 ビット、
小数部が 3 ビットの固定小数点表現としましょう。

この場合、
例えば 2 進数の 1\posn{2} は、
1.000\posn{2} \times 2^{0} ですので、
したがって、
指数が $e_3 e_2 e_1 e_0 \posn{2} = 0000\posn{2}$ となり、
係数が $c_3 c_2 c_1 c_0 \posn{2} = 1000\posn{2}$ となります。
このため 1\posn{2} は 00001000\posn{2} と表現できます。

同様に、
2 進数の 100111.110110\posn{2} (= 39.843 8) を表現してみましょう。
この値は 1.00111110110 \times 2^{5} と書けるため、
指数が $e_3 e_2 e_1 e_0 \posn{2} = 0101\posn{2}$ となり、
係数が $c_3 c_2 c_1 c_0 \posn{2} = 1001\posn{2}$ となります。
このため 10010101\posn{2} (= 36) のように表現できます。

なおこの場合、
係数は 4 ビットしかないため、
5 ビット目以降は単純に切り捨てています。
データの大きさが 8 ビットしかないので、
39.843 8 を 8 ビットに格納すると、
結果的に値は 36 になります (丸め誤差が生じます)。

*** IEEE 754 浮動小数点表現

現在、
コンピュータで扱われている浮動小数点表現は、
ほとんどの場合 *IEEE 754* という標準規格に従っています。
IEEE 754 は IEEE Standard for Floating-Point Arithmetic という名称で、
*IEEE (電気電子技術者協会)* において標準化された規格です。
もともとは 1985 年に発行された IEEE 754-1985 という規格でしたが、
2008 年に改訂されて、
今は IEEE 754-2008 となっています。

IEEE 754 も、
基本的には [[sec:floating-point-nubmer]] 節で説明したような浮動小数点表現の考え方をもとにしています。
ただし、
実用上の観点からさまざまな工夫が盛り込まれて、
その結果、
IEEE 754 はやや複雑なものとなっています。
そのため以下では、
IEEE 754 の概要のみを説明します。

IEEE 754 で規定されている浮動小数点表現は多岐にわたりますが、
特に広く用いられているのは以下の 3 つの形式です (図 [[fig:number/ieee754]])。
- *単精度 (single precision)*
- *倍精度 (double precision)*
- *拡張倍精度 (double extended precision)*
これらの形式では主に、
全体のビット数や、
係数や指数にそれぞれ何ビットを割り当てるかが異なっています (表 [[tab:number/ieee754]])。
なお、
IEEE 754 では、
[[sec:floating-point-nubmer]] 節で説明した係数は *仮数 (mantissa)* と呼ばれています (なぜ仮数と呼ばれているかについては後述します)。

#+caption: IEEE 754 で規定されている代表的な浮動小数点表現形式
#+label: fig:number/ieee754
#+attr_latex: :width \columnwidth
[[./figure/number/ieee754.png]]

#+caption: 代表的な IEEE 754 の表現形式
#+label: tab:number/ieee754
| 名称                                   | 全体 | 符号 | 仮数 | 指数 | バイアス |
|----------------------------------------+------+------+------+------+----------|
| 単精度 (single precision)              |   32 |    1 |   23 |    8 |      127 |
| 倍精度 (double precision)              |   64 |    1 |   52 |   11 |     1023 |
| 拡張倍精度 (double extended precision) |   80 |    1 |   63 |   15 |    16383 |
# https://en.wikipedia.org/wiki/Floating-point_arithmetic#IEEE_754:_floating_point_in_modern_computers

*単精度 (single precision)* は全体のビット数が 32 であり (図 [[fig:single]])、
係数 (仮数) と指数に、
それぞれ 23 ビットと 8 ビットが割り当てられています。
また、
残りの 1 ビットは符号ビットとなります。
多くの C コンパイラでは、
~float~ 型が IEEE 754 の単精度として実現されています。

#+caption: IEEE 754 単精度形式
#+label: fig:single
#+attr_latex: :width \columnwidth
[[./figure/number/single.png]]

それでは例として、
1.276 245 117 187 5 の単精度浮動小数点数表現を見てみましょう (図 [[fig:single]])。

まず、
最上位ビットが符号を表します。
ここでは値が 0 となっており、
非負であることを意味します。

単精度形式では、
符号ビットの次の 8 ビットが指数です。
この例では 01111111\posn{2} なので、
10 進数で 127 です。
IEEE 754 では、
後述するように、
指数にバイアスが加えられています。
単精度形式の指数部に格納されている値 127 は、
指数が 0 であることを意味しています (バイアス 127 を加えた値が格納されています)。

係数 (仮数) は残りの 23 ビット、
つまり 0100011 01011100 00000000\posn{2} です。
これも詳細は後ほど説明しますが、
この値は係数が 1.01000110 10111000 0000000\posn{2} であることを意味します。
この値は 10 進数では 1.276 245 117 187 5 であり、
図 [[fig:single]] より 1.276 245 117 187 5 \times 2^0 のように値が表現されていることがわかります。

いくつかの数を単精度形式に格納したときのビット列を表 [[tab:number/ieee754-single]] に示します。
表の左端が格納した 10 進数の値、
その右には丸め誤差の有無と IEEE 754 単精度形式に格納したときのビット列を示しています。
さらに、
ビット列を 32 ビットの符号なし整数として解釈したときの値 (10 進数) もあわせて示しています。

#+caption: IEEE 754 単精度形式に格納したときのビット列
#+label: tab:number/ieee754-single
#+attr_latex: :environment maxtabular
|                         10 進数 | 丸め誤差 | 2 進数 (単精度)                     | 10進数(単精度) |
|---------------------------------+----------+-------------------------------------+----------------|
|                               0 | なし     | 00000000 00000000 00000000 00000000 |             0  |
|                               1 | なし     | 00111111 10000000 00000000 00000000 | 1 065 353 216  |
|                              -1 | なし     | 10111111 10000000 00000000 00000000 | 3 212 836 864  |
|                              10 | なし     | 01000001 00100000 00000000 00000000 | 1 092 616 192  |
|                             -10 | なし     | 11000001 00100000 00000000 00000000 | 3 240 099 840  |
|                            1.23 | あり     | 00111111 10011101 01110000 10100100 | 1 067 282 596  |
|                           -1.23 | あり     | 10111111 10011101 01110000 10100100 | 3 214 766 244  |
|                          12 300 | なし     | 01000110 01000000 00110000 00000000 | 1 178 611 712  |
|                        0.004 56 | あり     | 00111011 10010101 01101100 00001101 |   999 648 269  |
| 0.000 000 000 000 000 000 000 1 | あり     | 00011010 11110001 11001001 00000001 |   452 053 249  |
|             1.276 245 117 187 5 | なし     | 00111111 10100011 01011100 00000000 | 1 067 670 528  |
| 602 214 076 000 000 000 000 000 | あり     | 01100110 11111111 00001100 00101110 | 1 727 990 830  |

この表から以下のようなことがわかります。
- 多くの場合に丸め誤差が発生している
- 0 の IEEE 754 単精度表現も 0 (すべてのビットがゼロ) である
- $x$ と $-x$ (例 1.23 と -1.23) の IEEE 754 単精度表現は符号ビットだけが異な
  る
- IEEE 754 単精度表現を符号なし整数に変換した値を見ても、格納されてい
  る値の大小はよくわからない
- ただしよく見ると、非負の数だけに着目すれば、元の数値の大小関係と、符
  号なし整数に変換した値の大小関係は同じである

単精度を理解したところで、
他の形式も見ていきましょう。

*倍精度 (double precision)* は、
文字通り、
全体のビット数が単精度の 2 倍の 64 ビットです。
係数と指数に、
それぞれ 52 ビットと 11 ビットが割り当てられています。
多くの C コンパイラでは、
~double~ 型が IEEE 754 の倍精度として実現されています。
C 言語における実数型の名前が ~double~ なのはここから来ているようです。
倍精度形式は単にビット数が増えただけで、
単精度形式と基本的な考え方はまったく同じです。

いくつかの数を倍精度形式に格納したときのビット列を表 [[tab:number/ieee754-double]] に示します。
表の見方は基本的に [[tab:number/ieee754-single]] と同じですが、
桁数が多くなったため、
符号なし整数として解釈したときの 10 進数の値は省略しています。
単精度形式と倍精度形式を比較すると、
単に指数と仮数のビット数が異なっているだけであることがわかります。

#+caption: IEEE 754 倍精度形式に格納したときのビット列
#+label: tab:number/ieee754-double
#+attr_latex: :environment maxtabular
|                         10 進数 | 丸め誤差 | 2 進数 (単精度)                                                         |
|---------------------------------+----------+-------------------------------------------------------------------------|
|                               0 | なし     | 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 |
|                               1 | なし     | 00111111 11110000 00000000 00000000 00000000 00000000 00000000 00000000 |
|                              -1 | なし     | 10111111 11110000 00000000 00000000 00000000 00000000 00000000 00000000 |
|                              10 | なし     | 01000000 00100100 00000000 00000000 00000000 00000000 00000000 00000000 |
|                             -10 | なし     | 11000000 00100100 00000000 00000000 00000000 00000000 00000000 00000000 |
|                            1.23 | あり     | 00111111 11110011 10101110 00010100 01111010 11100001 01000111 10101110 |
|                           -1.23 | あり     | 10111111 11110011 10101110 00010100 01111010 11100001 01000111 10101110 |
|                          12 300 | なし     | 01000000 11001000 00000110 00000000 00000000 00000000 00000000 00000000 |
|                        0.004 56 | あり     | 00111111 01110010 10101101 10000001 10101101 11101010 10001001 01110110 |
| 0.000 000 000 000 000 000 000 1 | あり     | 00111011 01011110 00111001 00100000 00010000 00010111 01011110 11100110 |
|             1.276 245 117 187 5 | なし     | 00111111 11110100 01101011 10000000 00000000 00000000 00000000 00000000 |
| 602 214 076 000 000 000 000 000 | あり     | 01000100 11011111 11100001 10000101 11001010 01010111 11000101 00010111 |

*拡張倍精度 (double extended precision)* は、
倍精度よりもさらにビット数の多い (より高精度な) 形式です。
全体のビット数は 80 です。
係数と指数に、
それぞれ 64 ビットと 15 ビットが割り当てられています。
C コンパイラによっては ~long double~ 型が IEEE 754 の拡張倍精度として実現されています。
拡張倍精度形式も単にビット数が増えただけです。
単精度形式、
倍精度形式と本質的には何も変わりません。

*** IEEE 754 における工夫

IEEE 754 には、
[[sec:floating-point-nubmer]] 節で説明したような素朴な浮動小数点表現に加えて、
さまざまな工夫が施されています。
IEEE 754 の興味深い点をいくつか紹介しましょう。

**** 係数 (仮数) の表現 (最上位ビットの省略)

IEEE 754 も浮動小数点表現の一種なので、
「係数 \times 2^{指数}」という形式で数を表現します。
なお、
IEEE 754 には 2 進数だけでなく、
10 進数の浮動小数点表現も規格に含まれていますが、
ここでは 2 進数の場合に話を限定します。

2 進数の浮動小数点表現の場合、
*係数の最上位ビットは (値がゼロの場合を除き) 必ず 1 である* という性質があります。
したがって、
IEEE 754 では、
最上位の係数 1 は格納せず、
2 桁目以降の係数を格納します。
これによって 1 ビット節約できる (言い換えれば 1 ビット分精度が向上する) ことになります。

[[sec:floating-point-nubmer]] 節と同じ例で説明しましょう。
IEEE 754 では 8 ビットのような小さなデータサイズは扱いませんが、
ここでは簡単のために、
[[sec:floating-point-nubmer]] 節と同じように 8 ビットの場合を考えます。
2 進数の 100111.110110\posn{2} (= 39.843 8) は 1.00111110 110\posn{2} \times 2^{5} と表現することができます。
これを、
例えば 8 ビットの浮動小数点表現 (指数部 4 ビット、
係数部 4 ビット) に格納する場合、
01011001\posn{2} (= 36) となることを [[sec:floating-point-nubmer]] 節で説明しました。

ここで、
係数の最上位ビットは通常は 1 であるという性質を利用し、
最上位の 1 を省略します。
つまり、
1.00111110 110\posn{2} \times 2^{5} の上位 4 ビットである 1.001\posn{2} を格納するのではなく、
2 ビット目から 5 ビット目までの 0011\posn{2} を格納すると、
01010011\posn{2} (= 38) のように表現されます。
なお、
浮動小数点表現された値を解釈する場合、
係数に格納されている値が $c_3 c_2 c_1 c_0 \posn{2}$ であれば、
実際の係数は、
先頭に 1\posn{2} があると見なして $1.c_3 c_2 c_1 c_0 \posn{2}$ として扱います。

上の例では、
元の値が 100111.110110\posn{2} (= 39.843 8) でした。
これを 8 ビットの浮動小数点として表現したときの値が、
36 から 38 に改善されています (誤差が小さくなっています)。
同じ 8 ビットを使った浮動小数点表現ですが、
表現法の工夫によって丸め誤差が小さくなっています。

#+begin_note
IEEE 754 の詳細を知るまで筆者は、
「コンピュータの浮動小数点表現では、
仮数と指数で値を表現する」といった記述を読んで、
「これの一体どこが『仮数』なんだろう?」
と疑問に思っていました。

漢字の「仮」は、
「仮の」とか「一時的な」といった意味です。
浮動小数点表現の仮数に、
「仮の」とか「一時的な」という性質があるようには思えません。
それなのに、
なぜ仮数という名前が付けられているのかが不思議でした。
この理由は以下のようなものだと考えられます。

IEEE 754 では係数の最上位ビットを保存しないため、
係数として保持するのは、
係数の小数部分のみになります。
先ほどの例 1.00111110 110\posn{2} \times 2^{5} では、
先頭の 1 を除いた .0011\posn{2} のみを係数として保存しています。

一方、
数学では、
*常用対数の小数部分* を mantissa と呼びます。
例えば 345 の常用対数
\begin{align}
  \log_{10} 345 = 2.537819095073274 \dots
\end{align}
の小数部分 0.537 819 095 073 274 \dots です。
そしてこの mantissa の日本語訳が「仮数」なのです。

こういった背景があり、
IEEE 754 の係数を仮数と呼んでいるのでしょう。
つまり、
- IEEE 754 の浮動小数点表現では係数の小数部分のみが保持される
- 常用対数の小数部分を表す mantissa (仮数) という用語がある
ということから、
浮動小数点表現の係数を仮数と呼ぶようになったのだと考えられます。
#+end_note

**** ゼロ、無限大、無効な値の表現

ただし、
係数の最上位の 1 を省略する (必ず最上位に 1 があると見なす) と、
ゼロの扱いに困ります。
ゼロは係数が 0 なので、
最上位が 1 ではありません。
そこで IEEE 754 では、
*一部の指数の値に特別な意味を持たせる* ことでゼロを表現しています。

表 [[tab:number/ieee754]] 中の *バイアス (bias)* は、
指数に対するオフセットを表しています。
IEEE 754 では、
指数の値をそのまま格納するのではなく、
*指数にバイアスを加えた値* を格納します。

ここで指数を $e$ とし、
バイアスを \Delta として、
浮動小数点表現として格納する指数の値 $e'$ とします。
IEEE 754 では、
この指数 $e$ をそのまま $e'$ に格納するのではなく、
指数 $e$ にバイアス \Delta を加えた
\begin{align}
  e' = e + \Delta
\end{align}
を指数の値として格納します。
そして逆に IEEE 754 の浮動小数点表現で格納された値を使用する場合は、
格納されている指数の値 $e'$ からバイアス \Delta を引いた
\begin{align}
  e = e' - \Delta
\end{align}
を実際の指数として用います。

例として、
1 を IEEE 754 の単精度形式で格納する場合で説明しましょう。
1 は指数表記では 1.0\posn{2} \times 2^0 です。
このため、
IEEE 754 の単精度形式では
- 符号に 0 (プラスを意味する) を格納する
- 仮数に 0000000 00000000 00000000\posn{2} (23 ビット) を格納する
- 指数に 0 + バイアス (127) = 127 = 01111111\posn{2} (8 ビット) を格納する
ことによって表現します。
指数に 0 をそのまま格納するのではなく、
0 にバイアス (単精度の場合 \Delta = 127) を加えた値を指数として格納するわけです。

IEEE 754 では、
指数に格納されている値 $e'$ が、
- *全ビットがすべて 0* である場合
- *全ビットがすべて 1* である場合
は特殊な値を意味します。
これらは通常の指数表記の値ではなく、
特殊な値が格納されていることを意味しており、
例えば、
単精度形式の場合、
指数が 00000000\posn{2} (= 0) であれば、
「特殊な値」だというわけです。

どのような特殊な値を意味するかは浮動小数点表現形式や仮数の値によって決まるのですが、
ここでは単精度形式の場合を説明します (表 [[tab:number/single-exp]])。

#+caption: IEEE 754 単精度形式における特殊な値
#+label: tab:number/single-exp
| 符号       |   指数 | 仮数(係数) | 意味                             |
|------------+--------+------------+----------------------------------|
| 0 または 1 |      0 | 0          | ゼロ                             |
| 0 または 1 |      0 | 0 でない   | 非正規化数 (denormalized number) |
| 0 または 1 | 1〜254 | 何でもよい | 「1.仮数」 \times 2^{指数-127}   |
| 0          |    255 | 0          | 無限大 (正の無限大)              |
| 1          |    255 | 0          | 無限大 (負の無限大)              |
| 0 または 1 |    255 | 0 でない   | 不正な値 (NaN; Not a Number)     |

まず、
指数が 0 で仮数も 0 の場合は *ゼロ* を意味します。
また符号ビットの値によらず、
指数が 0 で仮数も 0 である場合もゼロを意味します (このためプラスのゼロと、
マイナスのゼロの 2 つが存在します)。

指数が 0 で、
仮数が 0 でない場合は、
*非正規化数 (denormalized number)* と呼ばれる非常に小さな値を意味します。

他にも、
指数が 255 で仮数が 0 の場合は *無限大* となり、
符号ビットが 0 であれば *正の無限大* を、
符号ビットが 1 であれば *負の無限大* を意味します。
指数が 255 で、
仮数が 0 でない場合は、
*不正な値 (Not a Number; NaN)* を意味します。

IEEE 754 の仕様を読むと、
「ほー、
なるほど」と思う箇所がいくつもあります。
ぜひ時間があるときにでも IEEE 754 をじっくり学んでみてください。

** N 進数の計算に役立つツール
<<sec:number/tool>>

コンピュータのプログラムを読んだり書いたりする場合には、
10 進数だけでなく、
2 進数、
8 進数、
16 進数も扱う必要があります。
特に、
2 進数や 16 進数に習熟するという意味でも、
[[sec:number/binary]] 節や [[sec:number/hexadecimal]] 節で説明したような計算ができるようになっておいてください。

ただし、
毎回、
毎回、
2 進数、
8 進数、
10 進数、
16 進数の間の変換や計算を手で行っていては大変です。
そのため、
普段のプログラミングではツールを使って変換や計算を行いましょう。
こういったツールに普段から慣れ親しんでおけば、
何かあったときに即座に利用できるでしょう。

四則演算や、
2 進数、
8 進数、
10 進数、
16 進数の相互変換などは、
コンピュータにとって非常に基本的な計算です。
そのため、
これらの計算ができるツールは、
膨大な数存在します。
10 進数であればさまざまな電卓アプリケーションが存在し、
8 進数や 16 進数も使える、
関数電卓と呼ばれる高機能な電卓アプリケーションも多数存在します。

ここからは、
GNU/Linux や macOS など UNIX 系のオペレーティングシステムで標準的に利用できるツールをいくつか紹介します。
特に、
10 進数と 2 進数、
8 進数、
16 進数との相互変換や、
2 進数、
8 進数、
16 進数での計算に利用できるものを取り上げます。

なおここでは、
マウスで操作するような *GUI (Graphical User Interface)* ベースのものではなく、
キーボードだけ操作するような *CLI (Command Line Interface)* ベースのものを紹介していきます。
というのも、
GUI ベースのものは、
- 利用できる環境が制限される (常に GUI が使えるとは限らない)
- 起動時間も含めて、操作にどうしても時間がかかる
- 他のプログラムとの連携が容易ではない
などの理由でおすすめできないためです。

#+begin_note
コンピュータの内部ではすべて 2 進数で計算が行われていますが、
通常のプログラミングで主に使うのは 16 進数と 8 進数です。
そのため、
16 進数や 8 進数を扱えるツールは充実していますが、
逆に、
2 進数を直接扱えるようなものはあまり多くありません。
#+end_note

*** printf コマンド

GNU coreutils に含まれている ~printf~ コマンドを使えば、
10 進数の値を 16 進数に変換できます。
#+begin_src sh
$ printf '%x\n' 1234
4d2
#+end_src
~printf~ コマンドの *フォーマット指定子 (format specifier)* に ~%x~ を指定し、
引数の値を 16 進数で表示しています。
末尾の ~\n~ は改行を表示するためのものです。

~printf~ コマンドは、
C 言語の標準ライブラリに含まれている関数 ~printf~ と同じ名前ですが、
C 言語の関数ではありません。
~printf~ という名前の、
独立したコマンド (プログラム) であり、
GNU coreutils がインストールされたオペレーティングシステムであれば、
多くの場合、
~/usr/bin/printf~ にインストールされているはずです。

~printf~ コマンドでは、
C 言語の関数 ~printf~ と同じようなフォーマット指定子が使えます。
ただし、
フォーマット指定子 %x で扱えるのは整数のみです。
引数として実数を与えるとエラーになります。
#+begin_src sh
$ printf '%x\n' 1234.5678
1234.5678: value not completely converted
#+end_src

整数であれば、
10 進数の値を 8 進数に変換することもできます。
#+begin_src sh
$ printf '%o\n' 1234
2322
#+end_src

~printf~ コマンドは、
C 言語の数値と同じような形式で、
引数に 16 進数や 8 進数を記述することもできます。
このため、
16 進数から 10 進数への変換も可能です。
#+begin_src sh
$ printf '%d\n' 0x4d2
1234
#+end_src
この例では、
4d2\posn{16} の先頭の ~0x~ が 16 進数であることを意味します。
そしてフォーマット指定子に ~%d~ を指定し、
10 進数で出力しています。

同様に、
8 進数から 10 進数への変換も可能です。
8 進数の場合は先頭に 0 を付けて 02322 のように書きます。
#+begin_src sh
$ printf '%d\n' 02322
1234
#+end_src
2322 と書くと 10 進数の 2 322、
02322 と書くと 8 進数の 2322\posn{8} を意味します。

これらを組み合わせると、
10 進数、
16 進数、
8 進数の相互変換ができます。
例えば、
16 進数から 8 進数への変換は以下のようにします。
#+begin_src sh
$ printf '%o\n' 0x4d2
2322
#+end_src

他のツールと組み合わせればいろいろな計算も可能です。
例えば、
10 進数、
16 進数、
8 進数が混在した計算も可能です。
例として、
10 進数の 1 234 と、
16 進数の 1234\posn{16} (= 4 660)、
8 進数の 1234\posn{8} (= 668) の和を計算してみましょう。
#+begin_src sh
$ printf '%d+%d+%d\n' 1234 0x1234 01234 | bc
6562
#+end_src

さらに以下のようにすれば、
計算結果を 16 進数で表示することもできます。
#+begin_src sh
$ printf '%x\n' `printf '%d+%d+%d\n' 1234 0x1234 01234 | bc`
19a2
#+end_src
ここではバッククォート ~`~ を使ったシェルのコマンド置換を利用しています。

ただ、
残念ながら ~printf~ コマンドでは 2 進数を扱えません。
2 進数の値を引数として与えることもできませんし、
フォーマット指定子で 2 進数を表示させることもできません。

*** bc コマンド

~bc~ コマンドは、
UNIX に古くから存在する、
数値計算用のプログラミング言語です。
単なる電卓として使うことも可能ですが、
~bc~ コマンド自体は C 言語に似た文法を持つ、
数値計算用プログラミング言語のインタプリタです。

~bc~ コマンドは、
「いろいろ試してみればそのうち使い方がわかる」というコマンドではありません。
どう使えばいいのかがわかりづらく、
取っつきにくいものだといえますが、
一方で数値計算用のプログラミング言語なので、
使いこなせれば非常に高度なこともできるようになります。

~bc~ コマンドを起動して、
次のように対話的に操作すれば、
電卓として利用できます。
#+begin_src raw
$ bc
bc 1.07.1
Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundation, Inc.
This is free software with ABSOLUTELY NO WARRANTY.
For details type `warranty'.
1234 + 5678
6912
#+end_src
~bc~ コマンドはプロンプトを表示しないのでわかりづらいですが、
「1234 + 5678」が入力した行で、
「6912」が ~bc~ コマンドが出力した行になります。

ただし、
割り算をすると ???
となります。
#+begin_src raw
5/3
1
#+end_src

「なんだ、
~bc~ コマンドは整数演算しかできないのか」と思って、
多くの人はここで使うのを止めてしまうかもしれません (筆者も最初、
そう勘違いしました)。

~bc~ コマンドは任意精度の数値を扱える強力な数値計算プログラム言語です。
ただ、
デフォルトでは「整数で演算を行う設定」になっており、
~scale~ という特殊変数によって小数点以下の演算精度を変更する必要があります。
#+begin_src raw
scale=10
5/3
1.6666666666
#+end_src
ここでは、
~scale=10~ を指定し、
小数点以下 10 桁まで扱うよう指定しています。
任意精度が使えるので、
次のようなことも可能です。
#+begin_src raw
scale=1000
1234/567
2.176366843033509700176366843033509700176366843033509700176366843033\
50970017636684303350970017636684303350970017636684303350970017636684\
30335097001763668430335097001763668430335097001763668430335097001763\
66843033509700176366843033509700176366843033509700176366843033509700\
17636684303350970017636684303350970017636684303350970017636684303350\
97001763668430335097001763668430335097001763668430335097001763668430\
33509700176366843033509700176366843033509700176366843033509700176366\
84303350970017636684303350970017636684303350970017636684303350970017\
63668430335097001763668430335097001763668430335097001763668430335097\
00176366843033509700176366843033509700176366843033509700176366843033\
50970017636684303350970017636684303350970017636684303350970017636684\
30335097001763668430335097001763668430335097001763668430335097001763\
66843033509700176366843033509700176366843033509700176366843033509700\
17636684303350970017636684303350970017636684303350970017636684303350\
97001763668430335097001763668430335097001763668430
#+end_src
ここでは ~scale=1000~ を指定し、
小数点以下 1 000 桁まで有効にしています。

~bc~ コマンドでは、
特殊変数 ~ibase~ で入力の *基数 (radix)* を指定し、
~obase~ で出力の基数を指定します。
デフォルトではどちらも 10 (つまり、
入力も出力もどちらも 10 進数) になっていますが、
2 から 36 まで範囲で値を指定できます。

そのため、
2 進数、
8 進数、
16 進数だけでなく、
5 進数や、
12 進数、
36 進数など、
36 進数までのすべての N 進数を扱えます。

少し例を見てみましょう。
10 進数の 1234 を 16 進数に変換します。
#+begin_src sh
$ echo 'obase=16; 1234' | bc
4D2
#+end_src
ここでは、
~obase=16; 1234~ という ~bc~ コマンドのプログラムを ~echo~ コマンドで標準出力に表示しています。
そしてそれを、
~bc~ コマンドの標準入力にパイプでリダイレクトしています。

今度は 10 進数の 1234 を 8 進数に変換してみます。
#+begin_src sh
$ echo 'obase=8; 1234' | bc
2322
#+end_src

~bc~ コマンドでは 2 進数も扱えます。
#+begin_src sh
$ echo 'obase=2; 1234' | bc
10011010010
#+end_src

~bc~ コマンドは任意精度の数値が扱えるので、
整数だけでなく実数も扱えます。
#+begin_src sh
$ echo 'scale=20; 1234 / 567' | bc
2.17636684303350970017
#+end_src
ここでは ~scale=20~ を指定し、
小数点以下 20 桁を有効にしています。

素晴らしいことに、
実数の 2 進数も扱えます。
#+begin_src sh
$ echo 'scale=20; obase=2; 1234 / 567' | bc
10.00101101001001100110000010011110111011010111110100010000101101000\
11
#+end_src

あまり利用する場面は多くないかもしれませんが、
実数の 16 進数も扱えます。
#+begin_src sh
$ echo 'scale=20; obase=16; 1234 / 567' | bc
2.2D26609EED7D10B47
#+end_src

それでは逆に、
16 進数の 4d2\posn{16} を 10 進数に変換してみましょう。
#+begin_src sh
$ echo 'ibase=16; 4D2' | bc
1234
#+end_src
~bc~ コマンドでは、
16 進数には大文字の A〜F を使用します (小文字の a〜f を入力すると変数名と見なされてしまいます)。

次は 8 進数の 2322\posn{8} を 10 進数に変換してみます。
#+begin_src sh
$ echo 'ibase=8; 2322' | bc
1234
#+end_src
~ibase=8~ によって入力が 8 進数であることを指定しているため、
2322 の先頭に 0 を付けて 02322 とする必要はありません (付けても無視されるだけです)。

最後に、
2 進数の 10011010010\posn{2} を 10 進数に変換します。
#+begin_src sh
$ echo 'ibase=2; 10011010010 | bc
1234
#+end_src

~bc~ コマンドでは、
~printf~ コマンドと同様に、
10 進数、
16 進数、
8 進数の相互変換も可能です。
例えば、
16 進数から 8 進数への変換は以下のように行います。
#+begin_src sh
$ echo 'ibase=16; obase=8; 4D2' | bc
2322
#+end_src

#+begin_note
~ibase=16~ と指定した直後から、
入力する値がすべて 16 進数と見なされることに注意してください。
そのため、
~ibase=16~ と指定した直後の ~obase=8~ でも、
数値の「8」が 16 進数として解釈されます。

上記の例では問題が起こらないのですが、
以下のような場合は予想外の結果になります。

#+begin_src sh
$ echo 'ibase=8; obase=16; 2322' | bc
642
#+end_src

~ibase=8~ と指定した直後から、
入力する値がすべて 8 進数と見なされています。
~obase=16~ で 16 進数を指定したつもりですが、
8 進数の 16\posn{8} (= 14) と見なされているわけです。
その結果、
出力が 14 進数になり、
14 進数の 642\posn{14} が表示されています。
特に、
~bc~ コマンドを対話的に使っているときにこのように混乱しやすいので注意してください。
#+end_note

*** インタープリタ型言語を電卓として利用する

10 進数と、
2 進数、
8 進数、
16 進数の変換や簡単な計算には、
インタープリタ型の言語を電卓代わりに利用することもできます。

一例として、
Python を対話モードで起動して、
簡単な四則演算を行ってみましょう。
#+begin_src python
$ python3
Python 3.7.3 (default, Jul 25 2020, 13:03:44)
[GCC 8.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> 1234 + 5678
6912
>>> 1234 / 567
2.17636684303351
>>> (1234 + 5678) / 90123
0.07669518324955893
#+end_src

Python は 2 進数、
8 進数、
16 進数の数を扱えるので、
10 進数への変換は簡単です。
#+begin_src python
>>> 0b10011010010
1234
>>> 0x4d2
1234
>>> 0o2322
1234
#+end_src
Python では、
2 進数、
8 進数、
16 進数の数には、
先頭にそれぞれ ~0b~、
~0o~、
~0x~ を付与します。

10 進数の 1 234、
8 進数の 1234\posn{8}、
16 進数の 1234\posn{16} の和を計算するのも簡単です。
#+begin_src python
>>> 1234 + 0o1234 + 0x1234
6562
#+end_src

ただし、
2 進数、
8 進数、
16 進数の数として扱えるのは整数のみです。
実数は入力できません。
文法エラー (syntax error) になります。
#+begin_src python
>>> 0b10011010010.101011101
  File "<stdin>", line 1
    0b10011010010.101011101
                          ^
SyntaxError: invalid syntax
>>> 0x4d2.5f3c
  File "<stdin>", line 1
    0x4d2.5f3c
          ^
SyntaxError: invalid syntax
>>> 0o2322.07342
  File "<stdin>", line 1
    0o2322.07342
               ^
SyntaxError: invalid syntax
#+end_src

組み込みの関数 ~int~ を使って、
N 進数の文字列を 10 進数に変換することもできます。
#+begin_src python
>>> int('10011010010', base=2)
1234
>>> int('2322', base=8)
1234
>>> int('4d2', base=16)
1234
#+end_src

10 進数から 2 進数、
8 進数、
16 進数に変換する方法もいくつかあります。

まず、
10 進数から 2 進数への変換は、
1. 組み込み関数 ~bin~ を使う方法
2. 組み込み関数 ~format~ を使う方法
3. ~f~ 文字列の書式指定子を使う方法
などが挙げられます。
#+begin_src python
>>> bin(1234)
'0b10011010010'
>>> format(1234, 'b')
'10011010010'
>>> f'{1234:b}'
'10011010010'
#+end_src
タイプ量も少なく、
かつ覚えやすいのは関数 ~bin~ を使う方法でしょう。

10 進数から 8 進数への変換も同様です。
使用する関数が ~bin~ ではなく ~oct~ であることや、
書式指定子が ~b~ ではなく ~o~ となる点が異なります。
#+begin_src python
oct(1234)
'0o2322'
>>> format(1234, 'o')
'2322'
>>> f'{1234:o}'
'2322'
#+end_src

10 進数から 16 進数への変換も同様です。
関数 ~hex~ を使うか、
書式指定子に ~x~ を使います。
#+begin_src python
hex(1234)
'0x4d2'
>>> format(1234, 'x')
'4d2'
>>> f'{1234:x}'
'4d2'
#+end_src

ただし、
関数 ~bin~、
~oct~、
~hex~ で変換できるのは整数のみです。
実数を指定するとエラーになります (これらの関数の引数は ~int~ 型でなければなりません)。
#+begin_src python
>>> bin(1234.5678)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'float' object cannot be interpreted as an integer
>>> oct(1234.5678)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'float' object cannot be interpreted as an integer
>>> hex(1234.5678)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'float' object cannot be interpreted as an integer
#+end_src

*** プログラマ向け電卓プログラム ~ecalc~

アセンブリ言語で書かれたプログラムを読んだり、
書いたりするうえで、
2 進数、
8 進数、
16 進数は避けて通れません。
先ほど紹介したツールは、
一般的な UNIX 環境であれば大抵利用できるので、
いざという時に使えるようにしておきましょう。

しかし、
10 進数から 16 進数へ変換するたびに、
~bc~ コマンドを毎回起動して、
#+begin_src sh
$ echo 'obase=16; 1234' | bc
4D2
#+end_src
などと入力するのも面倒です。

同様に、
Python を対話モードで起動して、
#+begin_src python
$ python3
Python 3.7.3 (default, Jul 25 2020, 13:03:44)
[GCC 8.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> hex(1234)
'0x4d2'
#+end_src
などと毎回入力するのも面倒です。

そのため筆者としては、
2 進数、
8 進数、
16 進数を自在に扱えるような電卓プログラムを自分で作っておくことをおすすめします。
2 進数、
8 進数、
16 進数が扱えるような電卓プログラム程度であれば、
作るのは (作り方によりますが) それほど難しくありません。

#+begin_note
どのような言語で実装するかにもよりますが、
単体のハードウェア電卓のような電卓プログラムの作成はそれほど難しくありません。
すべてアセンブリ言語で記述するのは大変ですが、
C 言語や Java 言語のような高級言語であれば比較的簡単です。

ただし、
1 + 2 \times (3 + 4 / 5) / 6 のような式を正しく解釈できる電卓プログラムを作成するのはそれほど簡単ではありません。

私たちが普段使っている式は *中置記法 (infix notation)* と呼ばれる表記法になっており、
加算 (+) や乗算 (\times) のような二項演算は
#+begin_src raw
   123        +         456
   ---       ---        ---
オペランド  オペレータ オペランド
#+end_src
といった順序で並んでいます。
2 つのオペランドの間にオペレータが入るため、
中置記法と呼ばれるわけです。

中置記法の式を正しく解釈するプログラムを作成するには工夫が必要です。
というのも、
プログラミング言語のインタプリタやコンパイラがプログラムを解釈するのと同じように、
中置記法の式を解釈しなければならないからです。

ある程度プログラミングに慣れてきたら、
ぜひ中置記法の式を解釈できるような電卓プログラムを作成してみてください (コンパイラやインタプリタの作り方を学べば書けます)。
#+end_note

以下では、
私が普段使用している自作の電卓プログラム ecalc (https://github.com/h-ohsaki/ecalc) を紹介します。

#+begin_note
~ecalc~ には中置記法の式を入力できます。
ただし、
中置記法の式を解釈するプログラムは作成していません。
中置記法の式の解釈は複雑なので、
真面目に実装すると ~ecalc~ のような少ない行数では書けません (~ecalc~ はコメントを含めても 120 行程度のプログラムです)。

~ecalc~ に入力した中置記法の式は Python が解釈しています。
~ecalc~ に入力した式を Python の式に変換し、
Python インタプリタがその式の解釈・計算を行っています。
#+end_note

~ecalc~ は、
ネットワークエンジニアやネットワーク研究者向けに開発した電卓プログラムです。
~ecalc~ を使えば、
10 進数、
2 進数、
8 進数、
16 進数の相互変換や、
これらの値を使った計算が簡単にできます。
また、
ビットやバイト、
K (キロ)、
M (メガ)、
G (ギガ) など、
さまざまな単位が混在した計算を手軽に行うことができます。

~ecalc~ は Python で書かれたプログラムであり、
実行には Python バージョン 3 が必要です。
~ecalc~ は、
Python のソフトウェアリポジトリである PyPI (Python Package Index) から、
次のコマンドでインストールできます。

#+begin_src sh
$ sudo pip3 install ecalc
Collecting ecalc
  Using cached https://files.pythonhosted.org/packages/3b/19/1184cb1204ee49840bc78f5bd6e279f9947e29eb205b4e9e5f3209ebb8d6/ecalc-0.2-py3-none-any.whl
Collecting perlcompat (from ecalc)
  Downloading https://files.pythonhosted.org/packages/42/ab/328e564486228c8ed12085e4439fd39351e23333f52a8ed6833e4715efb8/perlcompat-1.1-py3-none-any.whl
Installing collected packages: perlcompat, ecalc
Successfully installed ecalc-0.2 perlcompat-1.1
#+end_src

~ecalc~ は ~perlcompat~ モジュールを使用しているため、
~perlcompat~ モジュールもあわせてインストールされています。
~ecalc~ の使い方は、
以下のマニュアル (日本語訳) を見てください。

*** 電卓プログラム ~ecalc~ のマニュアル

**** 名称

~ecalc~ - ネットワークエンジニア/研究者のための Pyhotn で書かれた単純な電卓

**** 起動方法

ecalc [-p #]

**** 説明

このマニュアルページは *ecalc* を説明しています。
このプログラムは、
対話的なテキストベースの電卓です。
Python で書かれており、
GNU readline ライブラリをサポートします。
*ecalc* は、
特にネットワークエンジニアやネットワーク研究者向けに設計されています。
ビット、
バイト、
パケット、
ビット / 秒などのネットワークに関連する単位を簡単に扱えます。

起動すると、
*ecalc* はプロンプト ~?~ を表示します。
ユーザは任意の式 (有効な Python の式) を入力することができます。
*ecalc* は入力された式をそのまま評価し、
結果を 10 進数形式で表示します。
*ecalc* は、
あわせて 16 進数、
8 進数、
2 進数で結果の値を表示します。

一般的な日常の利用では、
Python 標準の math モジュールからインポートされた、
以下の数学や定数が役立つでしょう。
数学関数の詳細については、
https://docs.python.org/3/library/math.html を参照してください。

- 関数

  ceil, comb, copysign, fabs, factorial, floor, fmod, frexp, fsum,
  gcd, isclose, isfinite, isinf, isnan, isqrt, lcm, ldexp, modf,
  nextafter, perm, prod, remainder, trunc, ulp, exp, expml, log,
  loglp, log2, log10, pow, sqrt, asin, atan, atan2, cos, dist, hypot,
  sin, tan, degrees, radians, acosh, asinh, atanh, cosh, sinh, tanh,
  erf, erfc, gamma, lgamma,

- 定数

  pi, e, tau, inf, nan

*ecalc* は GNU readline ライブラリをサポートしています。
このため、
Emacs ライクな (ユーザがカスタマイズ可能な) キー操作で、
入力行を対話的に編集することができます。
詳細は GNU readline ライブラリのマニュアルページを参照してください。

*ecalc* は以下の単位を解釈します。
単位は角括弧 ~[]~ で囲んで入力してください。

| 記号        | 意味      |
|-------------+-----------|
| s           | 秒        |
| m           | メートル  |
| bit         | ビット    |
| bps         | ビット/秒 |
| byte, B     | バイト    |
| pkt, packet | パケット  |

デフォルトのパケット長は 1 500 バイト (イーサネットの最大フレーム長) です。
*-p* オプションで変更することができます。

*ecalc* は以下の単位をサポートしています。

| 記号 | 意味             | スケール |
|------+------------------+----------|
| p    | ピコ (pico)      | 10^{-12}   |
| n    | ナノ (nano)      | 10^{-9}    |
| u    | マイクロ (micro) | 10^{-6}    |
| m    | ミリ (milli)     |10^{-3}     |
| k, K | キロ (kilo)      | 10^{3}     |
| M    | メガ (mega)      | 10^{6}     |
| G    | ギガ (giga)      | 10^{9}     |
| T    | テラ (tera)      | 10^{12}    |
| P    | ペタ (peta)      | 10^{15}    |

**** 実行例

ここでは、
*ecalc* の利用例を示します。

*ecalc* は一般的な電卓代わりに利用できますが、
基準となる単位は「秒」および「バイト」です。
単位が秒またはバイト以外の値は自動的に変換されます。
例えば、
1 000 [bit/ms] は 125 000 [byte/s] に自動的に変換されます。

以下の実行例を見てみてください。
#+begin_src python
? 1+2*(3+4/5)**6
%1 = 6022.872767999998
        1786 hex          13606 oct   00000000 00000000 00010111 10000110
       48.18 bit/ms   4.818e+04 bit/s        48.18 Kbit/s     0.04818 Mbit/s
       6.023 B/ms          6023 B/s          6.023 KB/s      0.006023 MB/s
    0.004015 pkt/ms       4.015 pkt/s    1.807e+12 m        1.807e+09 km
#+end_src

空白はあってもなくてもかまいません。
#+begin_src python
? 1 + 2 * (3 + 4 / 5) ** 6
%2 = 6022.872767999998
        1786 hex          13606 oct   00000000 00000000 00010111 10000110
       48.18 bit/ms   4.818e+04 bit/s        48.18 Kbit/s     0.04818 Mbit/s
       6.023 B/ms          6023 B/s          6.023 KB/s      0.006023 MB/s
    0.004015 pkt/ms       4.015 pkt/s    1.807e+12 m        1.807e+09 km
#+end_src

直前の結果は ~%~ で参照できます。
#+begin_src python
? % + 1
%3 = 6023.872767999998
        1787 hex          13607 oct   00000000 00000000 00010111 10000111
       48.19 bit/ms   4.819e+04 bit/s        48.19 Kbit/s     0.04819 Mbit/s
       6.024 B/ms          6024 B/s          6.024 KB/s      0.006024 MB/s
    0.004016 pkt/ms       4.016 pkt/s    1.807e+12 m        1.807e+09 km
#+end_src

過去の結果は ~%番号 ~ で参照できます。
#+begin_src python
? %1 - %2
%4 = 0.0
           0 hex              0 oct   00000000 00000000 00000000 00000000
           0 bit/ms           0 bit/s            0 Kbit/s           0 Mbit/s
           0 B/ms             0 B/s              0 KB/s             0 MB/s
           0 pkt/ms           0 pkt/s            0 m                0 km
#+end_src

さらに以下のように、
Python の組み込み関数も利用できます。
#+begin_src python
? int(%1)
%5 = 6022
        1786 hex          13606 oct   00000000 00000000 00010111 10000110
       48.18 bit/ms   4.818e+04 bit/s        48.18 Kbit/s     0.04818 Mbit/s
       6.022 B/ms          6022 B/s          6.022 KB/s      0.006022 MB/s
    0.004015 pkt/ms       4.015 pkt/s    1.807e+12 m        1.807e+09 km
? log(sin(1) + cos(2))
%6 = -0.8549036989769139
           0 hex              0 oct   00000000 00000000 00000000 00000000
   -0.006839 bit/ms      -6.839 bit/s    -0.006839 Kbit/s  -6.839e-06 Mbit/s
  -0.0008549 B/ms       -0.8549 B/s     -0.0008549 KB/s    -8.549e-07 MB/s
  -5.699e-07 pkt/ms  -0.0005699 pkt/s   -2.565e+08 m       -2.565e+05 km
#+end_src

*ecalc* では、
10 進数だけでなく、
2 進数、
8 進数、
16 進数の値が使えます。
#+begin_src python
? 1234 + 0b101100111 + 0o1234 + 0x1234
%7 = 6921
        1b09 hex          15411 oct   00000000 00000000 00011011 00001001
       55.37 bit/ms   5.537e+04 bit/s        55.37 Kbit/s     0.05537 Mbit/s
       6.921 B/ms          6921 B/s          6.921 KB/s      0.006921 MB/s
    0.004614 pkt/ms       4.614 pkt/s    2.076e+12 m        2.076e+09 km
#+end_src

Python の組み込み関数や ~math~ モジュールの関数の使用例をいくつか示します。
#+begin_src python
? sqrt(2943)
%8 = 54.249423960075376
          36 hex             66 oct   00000000 00000000 00000000 00110110
       0.434 bit/ms         434 bit/s        0.434 Kbit/s    0.000434 Mbit/s
     0.05425 B/ms         54.25 B/s        0.05425 KB/s     5.425e-05 MB/s
   3.617e-05 pkt/ms     0.03617 pkt/s    1.627e+10 m        1.627e+07 km
  ? abs(%)
%9 = 54.249423960075376
          36 hex             66 oct   00000000 00000000 00000000 00110110
       0.434 bit/ms         434 bit/s        0.434 Kbit/s    0.000434 Mbit/s
     0.05425 B/ms         54.25 B/s        0.05425 KB/s     5.425e-05 MB/s
   3.617e-05 pkt/ms     0.03617 pkt/s    1.627e+10 m        1.627e+07 km
? abs(-%)
%10 = 54.249423960075376
          36 hex             66 oct   00000000 00000000 00000000 00110110
       0.434 bit/ms         434 bit/s        0.434 Kbit/s    0.000434 Mbit/s
     0.05425 B/ms         54.25 B/s        0.05425 KB/s     5.425e-05 MB/s
   3.617e-05 pkt/ms     0.03617 pkt/s    1.627e+10 m        1.627e+07 km
#+end_src

伝送速度を複数の単位に変換する例は以下のとおりです。
#+begin_src python
? 123 [packet/ms]
%11 = 184500000.0
     aff3f20 hex     1277637440 oct   00001010 11111111 00111111 00100000
   1.476e+06 bit/ms   1.476e+09 bit/s    1.476e+06 Kbit/s        1476 Mbit/s
   1.845e+05 B/ms     1.845e+08 B/s      1.845e+05 KB/s         184.5 MB/s
         123 pkt/ms    1.23e+05 pkt/s    5.535e+16 m        5.535e+13 km
#+end_src
上記の結果から、
パケット長が 1 500 [byte] (デフォルト設定) の場合、
123 [packet/ms] は、
例えば 1 476 [Mbit/s] に相当することがわかります。

そして伝送速度と通信時間の積から、
転送されたデータの総量が求まります。
#+begin_src python
? % * 10 [s]
%12 = 1845000000.0
    6df87740 hex    15576073500 oct   01101101 11111000 01110111 01000000
   1.476e+07 bit/ms   1.476e+10 bit/s    1.476e+07 Kbit/s   1.476e+04 Mbit/s
   1.845e+06 B/ms     1.845e+09 B/s      1.845e+06 KB/s          1845 MB/s
        1230 pkt/ms    1.23e+06 pkt/s    5.535e+17 m        5.535e+14 km
#+end_src
ここから、
123 [packet/ms] の転送速度で 10 秒間送信し続けると、
総転送量が 1 845 [MB] になることがわかります。

データ量を通信時間で割った値が伝送速度です。
#+begin_src python
? 6.4[Gbyte]/120[s]
%13 = 53333333.333333336
     32dcd55 hex      313346525 oct   00000011 00101101 11001101 01010101
   4.267e+05 bit/ms   4.267e+08 bit/s    4.267e+05 Kbit/s       426.7 Mbit/s
   5.333e+04 B/ms     5.333e+07 B/s      5.333e+04 KB/s         53.33 MB/s
       35.56 pkt/ms   3.556e+04 pkt/s      1.6e+16 m          1.6e+13 km
#+end_src
これより、
6.4 [Gbyte] を 120 秒かかって転送した場合、
ネットワークの伝送速度は 426.7 [Mbit/s] であることがわかります。

ネットワークの帯域遅延積 (bandwidth-delay-product) を計算します。
#+begin_src python
? 64[packet] * 1200[ms]
%14 = 115200.0
       1c200 hex         341000 oct   00000000 00000001 11000010 00000000
       921.6 bit/ms   9.216e+05 bit/s        921.6 Kbit/s      0.9216 Mbit/s
       115.2 B/ms     1.152e+05 B/s          115.2 KB/s        0.1152 MB/s
      0.0768 pkt/ms        76.8 pkt/s    3.456e+13 m        3.456e+10 km
#+end_src
これは例えば、
ウィンドウサイズが 64 [packet] で、
ラウンドトリップ時間が 120 [ms] の場合、
TCP のウィンドウフロー制御は少なくとも 11.52 [KB] の TCP ソケットバッファが必要であることを示しています。

単位がメートルであれば、
その値は秒 (光の速度でその距離を移動するのに要する時間) に変換されます。
#+begin_src python
? 128[km]
%15 = 0.00042666666666666667
           0 hex              0 oct   00000000 00000000 00000000 00000000
   3.413e-06 bit/ms    0.003413 bit/s    3.413e-06 Kbit/s   3.413e-09 Mbit/s
   4.267e-07 B/ms     0.0004267 B/s      4.267e-07 KB/s     4.267e-10 MB/s
   2.844e-10 pkt/ms   2.844e-07 pkt/s     1.28e+05 m              128 km
#+end_src
これは、
光が 128 [km] を 0.000426 [s] で移動することを示しています。

逆に、
単位が秒であれば、
その値はメートルに換算されます。
#+begin_src python
? 0.0012[ms]
%16 = 1.2e-06
           0 hex              0 oct   00000000 00000000 00000000 00000000
     9.6e-09 bit/ms     9.6e-06 bit/s      9.6e-09 Kbit/s     9.6e-12 Mbit/s
     1.2e-09 B/ms       1.2e-06 B/s        1.2e-09 KB/s       1.2e-12 MB/s
       8e-13 pkt/ms       8e-10 pkt/s          360 m             0.36 km
#+end_src
これより、
光は 0.0012 [ms] で 0.36 [km] 移動することがわかります。

**** 入手先

最新版の *ecalc* は https://pypi.org/project/ecalc/ から入手できます。

**** 作者

大崎 博之 <ohsaki[atmark]lsnl.jp>

** 章末問題
<<sec:number/quiz>>

1. 10 進数の 17、79、227、823 をそれぞれ 2 進数で表せ。

   #+begin_answer
   10001\posn{2}、
   1001111\posn{2}、
   11100011\posn{2}、
   110111\posn{2}
   #+end_answer

2. 00010111\posn{2}、10010111\posn{2}、110111011\posn{2}、
   1100000001\posn{2} をそれぞれ 10進数で表せ。

   #+begin_answer
   23、
   151、
   443、
   769
   #+end_answer

3. 1000111\posn{2} + 0011111\posn{2}、1011100011\posn{2} +
   0100111001\posn{2}、1111010111\posn{2} + 1100101011\posn{2} をそれ
   ぞれ筆算で求めよ。

4. 1000111\posn{2} - 0011111\posn{2}、1011100011\posn{2} -
   0100111001\posn{2}、1111010111\posn{2} - 1100101011\posn{2} をそれ
   ぞれ筆算で求めよ。

5. 上の計算の正しさを、2 進数を 10 進数に変換した値の加算および減算に
   よって確認せよ。

6. 10 進数の 17、79、227、823 をそれぞれ 16 進数で表せ。

   #+begin_answer
   0x11、
   0x4f、
   0xe3、
   0x337
   #+end_answer

7. 0x17、0x97、0x1bb、0x301 をそれぞれ 10 進数で表せ。

   #+begin_answer
   23、
   151、
   443、
   769
   #+end_answer

8. 0x47 + 0x1f、0x2e3 + 0x139、0x3d7 + 0x32b をそれぞれ筆算で求めよ。

9. 0x47 - 0x1f、0x2e3 - 0x139、0x3d7 - 0x32b をそれぞれ筆算で求めよ。

10. 上の計算の正しさを、16 進数を 10 進数に変換した値の加算および減算
    によって確認せよ。

11. 16 進数の 0x17、0x97、0x1bb、0x301 をそれぞれ 2 進数で表せ。

    #+begin_answer
    10111\posn{2}、
    10010111\posn{2}、
    1 10111011\posn{2}、
    11 00000001\posn{2}
    #+end_answer

12. 00010111\posn{2}、10010111\posn{2}、110111011\posn{2}、
    1100000001\posn{2} をそれぞれ 16 進数で表せ。

    #+begin_answer
    0x17、
    0x97、
    0x1bb、
    0x301
    #+end_answer

13. 好きなプログラミング言語を用いて、標準入力から 10 進の非負整数を読
    み込み、その値を標準出力に 2進数、10 進数、16 進数で出力するプログ
    ラムを作成せよ。

    #+begin_answer
    - 簡単なプログラムの例: ~conv.py~ (図 [[fig:number/ex/conv.py]])
    - より複雑なプログラムの例: https://github.com/h-ohsaki/ecalc
    #+caption: number/ex/conv.py
    #+label: fig:number/ex/conv.py
    #+include: "code/number/ex/conv.py" src python
    #+end_answer

14. 上のプログラムを利用して、本章の問題への回答が正しいかを確認せよ。
